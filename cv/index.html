<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
		<meta name="author" content="Yannis Avrithis">
		<meta name="description" content="Yannis Avrithis - Home page">
		<meta name="keywords" content="Yannis Avrithis computer vision machine learning deep learning image search indexing retrieval">
		<title>Yannis Avrithis - Resume</title>

		<!-- bootstrap -->
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
		<script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>

		<!-- fonts -->
		<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,500" rel="stylesheet">
		<link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:300" rel="stylesheet">

		<!-- mathjax -->
		<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>
		<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML" async></script>

		<!-- font awesome -->
		<script defer src="../web/js/fa.js"></script>

		<!-- styles -->
		<link rel="stylesheet" href="../web/css/home.css">

		<!-- scripts -->
		<script src="../web/js/bs-docs.min.js"></script>
		<script src="../web/js/email.js"></script>
		<script src="../web/js/scroll.js"></script>

	</head>
	<body data-spy="scroll" data-target="#nav">
		<header class="navbar navbar-expand navbar-dark flex-column flex-md-row bd-navbar">
			<a class="navbar-brand mr-0 mr-md-2 brand" href="../">Y</a>
			<div class="navbar-nav-scroll">
				<ul class="navbar-nav bd-navbar-nav flex-row">
					<li class="nav-item">
						<a class="nav-link" href="../">Home</a>
					</li>
					<li class="nav-item">
						<a class="nav-link active" href="../cv">Resume</a>
					</li>
					<li class="nav-item">
						<a class="nav-link" href="../pub">Publications</a>
					</li>
					<li class="nav-item">
						<a class="nav-link" href="../code">Code & Data</a>
					</li>
					<li class="nav-item">
						<a class="nav-link" href="../time">Timeline</a>
					</li>
				</ul>
			</div>
			<ul class="navbar-nav flex-row ml-md-auto d-none d-md-flex">
				<li class="nav-item">
					<script>ema(ema_net(), "nav-link p-2");</script>
						<i class="fal fa-at"></i>
					</a>
				</li>
				<li class="nav-item">
					<a class="nav-link p-2" href="https://arxiv.org/search/?searchtype=author&query=Avrithis%2C+Y">
						<div class="arxiv">X</div>
					</a>
				</li>
				<li class="nav-item">
					<a class="nav-link p-2" href="https://dblp.org/pers/hd/a/Avrithis:Yannis">
						<i class="faa fa-dblp" data-fa-transform="grow-32 down-14 right-12"></i>
					</a>
				</li>
				<li class="nav-item">
					<a class="nav-link p-2" href="https://scholar.google.com/citations?user=AF2SxG0AAAAJ&sortby=pubdate">
						<i class="fal fa-atom" data-fa-transform="rotate-90"></i>
					</a>
				</li>
				<li class="nav-item">
					<a class="nav-link p-2" href="https://www.linkedin.com/in/yannisavrithis/">
						<i class="fab fa-linkedin-in"></i>
					</a>
				</li>
				<li class="nav-item">
					<a class="nav-link p-2" href="https://github.com/iavr">
						<i class="fab fa-github"></i>
					</a>
				</li>
			</ul>
		</header>


<div class="container-fluid" id="cv">
	<div class="row">

		<div class="col-md-auto side-bar">
			<nav id="nav">
				<div class="nav side-nav">
					<a class="nav-link" href="#summary">
						<span class="icon"><i class="fal fa-stopwatch"></i></span>
						<span class="desc-md">Summary</span>
					</a>
					<a class="nav-link" href="#down">
						<span class="icon"><i class="fal fa-download"></i></span>
						<span class="desc-md">Download</span>
					</a>
					<a class="nav-link" href="#inter">
						<span class="icon"><i class="fal fa-snowboarding"></i></span>
						<span class="desc-md">Interests</span>
					</a>
					<a class="nav-link" href="#edu">
						<span class="icon"><i class="fal fa-university"></i></span>
						<span class="desc-md">Education</span>
					</a>
					<a class="nav-link" href="#member">
						<span class="icon"><i class="fal fa-address-card"></i></span>
						<span class="desc-md">Memberships</span>
					</a>
					<a class="nav-link" href="#job">
						<span class="icon"><i class="fal fa-briefcase"></i></span>
						<span class="desc-md">Employment</span>
					</a>
					<a class="nav-link" href="#teach">
						<span class="icon"><i class="fal fa-chalkboard-teacher"></i></span>
						<span class="desc-md">Teaching</span>
					</a>
					<a class="nav-link" href="#talk">
						<span class="icon"><i class="fal fa-podium"></i></span>
						<span class="desc-md">Talks</span>
					</a>
					<a class="nav-link" href="#phd">
						<span class="icon"><i class="fal fa-user-graduate"></i></span>
						<span class="desc-md">Students</span>
					</a>
					<a class="nav-link" href="#eu">
						<span class="icon"><i class="fal fa-coins"></i></span>
						<span class="desc-md">Grants</span>
					</a>
					<a class="nav-link" href="#act">
						<span class="icon"><i class="fal fa-chart-network"></i></span>
						<span class="desc-md">Conferences</span>
					</a>
					<a class="nav-link" href="#jury">
						<span class="icon"><i class="fal fa-diploma"></i></span>
						<span class="desc-md">Juries</span>
					</a>
					<a class="nav-link" href="#eval">
						<span class="icon"><i class="fal fa-balance-scale"></i></span>
						<span class="desc-md">Evaluation</span>
					</a>
					<a class="nav-link" href="#edit">
						<span class="icon"><i class="fal fa-pen-nib"></i></span>
						<span class="desc-md">Editorial</span>
					</a>
					<a class="nav-link" href="#journ">
						<span class="icon"><i class="fal fa-book-reader"></i></span>
						<span class="desc-md">Reviewing</span>
					</a>
				</div>
			</nav>
		</div>

		<main class="col-md">
			<div class="container bottom-pad">
				<h1 class="cv rule">
					<a class="anchor" id="summary"></a>
					<span class="mr">Summary</span>
					<i class="fal fa-stopwatch"></i>
				</h1>
				<div class="just">
					Dr. Yannis Avrithis is a Research Director in the <a href="https://www.athenarc.gr/en/imsi/">Information Management Systems Institute</a> of <a href="https://www.athenarc.gr/en/">Athena Research Center</a>, carrying out research on computer vision and machine learning. Before that he was at the <a href="https://www-linkmedia.irisa.fr/">LinkMedia</a> team of <a href="http://www.inria.fr/en/centre/rennes">Inria Rennes-Bretagne Atlantique</a>, France, at the <a href="https://en.uoa.gr/">National and Kapodistrian University of Athens (NKUA)</a> and at the <a href="https://www.ntua.gr/en/">National Technical University of Athens (NTUA)</a>, Greece, where he lead the <a href="http://image.ntua.gr/iva/">Image and Video Analysis (IVA)</a> team. He holds the <a href="https://www.univ-rennes1.fr/habilitation-diriger-des-recherches-hdr">HDR</a> qualification from <a href="https://www.univ-rennes1.fr/en">University of Rennes 1</a>, PhD and Diploma degrees from NTUA and MSc degree from <a href="https://www.imperial.ac.uk/">Imperial College</a>, University of London, UK. He has been involved in 16 European, 6 French and 10 Greek research projects, he has co-supervised 17 Ph.D. theses and 19 Diploma/Masters theses, and he has published 4 theses, 3 edited volumes, 30 articles in journals, 117 in conferences and workshops, 8 book chapters and 31 technical reports in the above fields. He has contributed to the organization of 23 conferences and workshops. He has served as associate editor in 2 scientific journals and as a reviewer in 15 journals and 15 conferences. He is a senior member of <a href="http://www.ieee.org/">IEEE</a> and a member of <a href="https://ellis.eu/">ELLIS</a>, <a href="http://www.acm.org/">ACM</a>, <a href="http://www.eurasip.org/">EURASIP</a> and the <a href="http://www.tee.gr/">Technical Chamber of Greece</a>.
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="down"></a>
					<span class="mr">Download</span>
					<i class="fal fa-download"></i>
				</h1>
				<a class="btn acro" href="../files/cv.pdf">
					<span class="mr">Complete Resume</span>
					<i class="faa fa-file-pdf2"></i>
					<div class="cv-ref">
						Last updated:
						Sep 26, 2021
					</div>
				</a>
				<h1 class="cv rule">
					<a class="anchor" id="inter"></a>
					<span class="mr">Research interests</span>
					<i class="fal fa-snowboarding"></i>
				</h1>
				<div class="just">
					Visual feature detection, representation of visual appearance and geometry, image matching and registration, image indexing and retrieval, clustering, nearest neighbor search, visual representation learning, unsupervised and semi-supervised learning, object detection and recognition, scene classification, image/video segmentation and tracking, and video summarization.
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="edu"></a>
					<span class="mr">Education / Qualifications</span>
					<i class="fal fa-university"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="edu-2020"></a>
						<div class="cv-year">
							2020
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">HDR in <a href="https://www.univ-rennes1.fr/habilitation-diriger-des-recherches-hdr">Computer Science</a></span>
						</div>
						<a href="https://www.univ-rennes1.fr/en">University of Rennes 1</a> <span class="bull"></span> France
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="edu-1996"></a>
						<div class="cv-year">
							1996-2001
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Ph.D. in <a href="https://www.ece.ntua.gr/en">Electrical and Computer Engineering</a></span>
						</div>
						<a href="https://www.ntua.gr/en/">National Technical University of Athens</a> <span class="bull"></span> Greece
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="edu-1993"></a>
						<div class="cv-year">
							1993-1994
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">M.Sc. in <a href="https://imperial.ac.uk/electrical-engineering/research/comms-and-signal-processing/">Communications and Signal Processing</a></span>
							<span class="xtra but">Distinction</span>
						</div>
						<em><a href="https://imperial.ac.uk/">Imperial College of Science, Technology and Medicine</a></em><br>
						<a href="https://london.ac.uk/">University of London</a> <span class="bull"></span> UK
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="edu-1988"></a>
						<div class="cv-year">
							1988-1993
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Diploma/M.Eng. in <a href="https://www.ece.ntua.gr/en">Electrical and Computer Engineering</a></span>
						</div>
						<a href="https://www.ntua.gr/en/">National Technical University of Athens</a> <span class="bull"></span> Greece
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="member"></a>
					<span class="mr">Professional memberships</span>
					<i class="fal fa-address-card"></i>
				</h1>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="member-2021-ellis"></a>
						<div class="cv-year">
							2021-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Member <span class="bull"></span>
							<a class="mr" href="https://ellis.eu/">European Lab for Learning and Intelligent Systems</a>
				
							<a class="but acro" href="https://ellis.eu/">ELLIS</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="member-2019-ieee"></a>
						<div class="cv-year">
							2019-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Senior Member <span class="bull"></span>
							<a class="mr" href="http://www.ieee.org/">Institute of Electrical and Electronics Engineers</a>
				
							<a class="but acro" href="http://www.ieee.org/">IEEE</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="member-2001-eurasip"></a>
						<div class="cv-year">
							2001-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Member <span class="bull"></span>
							<a class="mr" href="http://www.eurasip.org/">European Signal Processing Society</a>
				
							<a class="but acro" href="http://www.eurasip.org/">EURASIP</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="member-1998-acm"></a>
						<div class="cv-year">
							1998-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Member <span class="bull"></span>
							<a class="mr" href="http://www.acm.org/">Association of Computing Machinery</a>
				
							<a class="but acro" href="http://www.acm.org/">ACM</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="member-1996-ieee"></a>
						<div class="cv-year">
							1996-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Member <span class="bull"></span>
							<a class="mr" href="http://www.ieee.org/">Institute of Electrical and Electronics Engineers</a>
				
							<a class="but acro" href="http://www.ieee.org/">IEEE</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="member-1994-tcg"></a>
						<div class="cv-year">
							1994-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Member <span class="bull"></span>
							<a class="mr" href="http://www.tee.gr/">Technical Chamber of Greece</a>
				
							<a class="but acro" href="http://www.tee.gr/">TCG</a>
						</div>
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="job"></a>
					<span class="mr">Employment history</span>
					<i class="fal fa-briefcase"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="job-2021"></a>
						<div class="cv-year">
							2021-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Research Director
						</div>
						<em><a href="https://www.athenarc.gr/en/imsi/">Information Management Systems Institute</a></em><br>
						<a href="https://www.athenarc.gr/en/">Athena Research Center</a>
						<div class="cv-ref">
							Artemidos 6 & Epidavrou, 15125 Marousi, Greece
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="job-2016"></a>
						<div class="cv-year">
							2016-2021
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Research Scientist
						</div>
						<em><a href="https://www-linkmedia.irisa.fr/">LinkMedia team</a></em><br>
						<a href="http://www.inria.fr/en/centre/rennes">Inria Rennes-Bretagne Atlantique</a>
						<div class="cv-ref">
							Campus de Beaulieu, 35042 Rennes Cedex, France
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="job-2015"></a>
						<div class="cv-year">
							2015
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Research Scientist
						</div>
						<em><a href="http://erga.di.uoa.gr/">Laboratory of Algebraic and Geometric Algorithms</a></em><br>
						<a href="https://en.uoa.gr/">National and Kapodistrian University of Athens</a>
						<div class="cv-ref">
							Panepistimioupolis, 157 84 Ilissia, Greece
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="job-2014"></a>
						<div class="cv-year">
							2014-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Scientific Advisor
						</div>
						<a href="https://oddconcepts.kr/index.en.html">Odd Concepts Inc.</a>
						<div class="cv-ref">
							5F Sambo BD, 5 Teheran-ro19-gil, Gangnam-gu, Seoul, Korea
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="job-2001"></a>
						<div class="cv-year">
							2001-2014
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Senior Researcher
						</div>
						<em><a href="http://image.ntua.gr/">Image, Video and Multimedia Systems Laboratory</a></em><br>
						<a href="https://www.ntua.gr/en/">National Technical University of Athens</a>
						<div class="cv-ref">
							9 Iroon Polytechniou Str., 157 73 Zographou, Greece
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="job-2002"></a>
						<div class="cv-year">
							2002-2004
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Project Manager, Research & Development
						</div>
						<a href="http://syntax.gr/">Syntax IT, Inc.</a>
						<div class="cv-ref">
							218 Mesogion Ave., 155 61 Holargos, Athens, Greece
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="job-1997"></a>
						<div class="cv-year">
							1997-1999
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Software Engineer
						</div>
						<a href="https://web.archive.org/web/*/https://www.infolabmm.gr/*">Infolab Multimedia Ltd</a>
						<div class="cv-ref">
							320 Mesogion Ave., 155 62 Holargos, Athens, Greece
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="job-1995"></a>
						<div class="cv-year">
							1995-1997
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							System Administrator
						</div>
						<em><a href="http://image.ntua.gr/">Image, Video and Multimedia Systems Laboratory</a></em><br>
						<a href="https://www.ntua.gr/en/">National Technical University of Athens</a>
						<div class="cv-ref">
							9 Iroon Polytechniou Str., 157 73 Athens, Greece
						</div>
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="teach"></a>
					<span class="mr">Teaching / training activities</span>
					<i class="fal fa-chalkboard-teacher"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-2021-paiss"></a>
						<div class="cv-year">
							2021
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Social Guest</span>
				
							<a class="but acro" href="https://project.inria.fr/paiss/paiss-2021/">PAISS&nbsp;2021</a>
						</div>
						<a href="https://project.inria.fr/paiss/paiss-2021/"><em>PRAIRIE/MIAI Artificial Intelligence Summer School</em></a>
						<div class="cv-ref">
							Summer School <span class="bull"></span> Virtual <span class="bull"></span> July 5-9, 2021
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-2021-dlcv"></a>
						<div class="cv-year">
							2021
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						Instructor
							<span class="bull"></span>
							<span class="mr">Deep Learning and Computer Vision</span>
				
							<a class="but acro" href="https://en.uoa.gr/">NKUA</a>
						</div>
						<div class="cv-ref">
							Doctoral School
						</div>
						<em><a href="http://grapes-network.eu/event/doctoral-school-i-midterm-meeting/">GRAPES Doctoral school I</a></em><br>
						<a href="https://en.uoa.gr/">National and Kapodistrian University of Athens</a>
						<div class="cv-ref">
							Seminar <span class="bull"></span> Virtual <span class="bull"></span> February 1-8, 2021
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-2019-cv"></a>
						<div class="cv-year">
							2019-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						Visiting Professor
							<span class="bull"></span>
							<span class="mr">Computer Vision</span>
				
							<a class="but acro" href="https://en.uoa.gr/">NKUA</a>
						</div>
						<div class="cv-ref">
							Interdisciplinary postgraduate program
						</div>
						<em><a href="http://dsit.di.uoa.gr/">MSc in Data Science & Information Technologies (DSIT)</a></em><br>
						<a href="https://en.uoa.gr/">National and Kapodistrian University of Athens</a> <span class="bull"></span> Greece
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-2018-dlcv"></a>
						<div class="cv-year">
							2018
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-teach-2018-dlcv">
							<i class="left-60 tog far fa-chevron-down"></i>
							Instructor
						</a>
							<span class="bull"></span>
							<span class="mr">Deep Learning for Computer Vision</span>
				
							<a class="but acro" href="https://en.uoa.gr/">NKUA</a>
						</div>
						<div class="cv-ref">
							Interdisciplinary postgraguate program
						</div>
						<em><a href="http://itmb.di.uoa.gr/indexEng.html">Information Technologies in Medicine and Biology (ITMB)</a></em><br>
						<a href="https://en.uoa.gr/">National and Kapodistrian University of Athens</a>
						<div class="cv-ref">
							Seminar <span class="bull"></span> Athens, Greece <span class="bull"></span> May 10-11, 2018
						</div>
						<div class="collapse" id="col-teach-2018-dlcv">
							<div class="cv-detail just">
								<p>
									In this two-day seminar I have focused on parts of the <a href="https://sif-dlv.github.io/">Deep Learning for Vision</a> course. In particular, visual representation, learning, convolution, differentiation, optimization, and network architectures. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-2017-dlv"></a>
						<div class="cv-year">
							2017-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-teach-2017-dlv">
							<i class="left-60 tog far fa-chevron-down"></i>
							Visiting Professor
						</a>
							<span class="bull"></span>
							<a class="mr" href="https://sif-dlv.github.io/">Deep Learning for Vision</a>
				
							<a class="but acro" href="https://www.univ-rennes1.fr/en">UR1</a>
						</div>
						<div class="cv-ref">
							Interdepartmental master
						</div>
						<em><a href="http://master.irisa.fr/">Research in Computer Science (SIF)</a></em><br>
						<a href="https://www.univ-rennes1.fr/en">University of Rennes 1</a>, University of Southern Brittany (UBS), ENS Rennes, National Institute of Applied Sciences (INSA), CentraleSupélec <span class="bull"></span> Rennes, France
						<div class="collapse" id="col-teach-2017-dlv">
							<div class="cv-detail just">
								<p>
									I am the course responsible. This course studies learning visual representations for common computer vision tasks including matching, retrieval, classification, and object detection. The course discusses well-known methods from low-level description to intermediate representation, and their dependence on the end task. It then studies a data-driven approach where the entire pipeline is optimized jointly in a supervised fashion, according to a task-dependent objective. Deep learning models are studied in detail and interpreted in connection to conventional models. The focus of the course is on recent, state of the art methods and large scale applications. The course syllabus includes visual representation, local features and spatial matching, codebooks and kernels, learning, differentiation, convolution, optimization, network architectures, object detection, and retrieval. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-2007-iva"></a>
						<div class="cv-year">
							2007-2014
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-teach-2007-iva">
							<i class="left-60 tog far fa-chevron-down"></i>
							Adjunct Professor
						</a>
							(407/80: 2008-2010)
							<span class="bull"></span>
							<a class="mr" href="http://image.ntua.gr/courses_static/dip/">Image and Video Analysis</a>
				
							<a class="but acro" href="https://www.ntua.gr/en/">NTUA</a>
						</div>
						<em><a href="https://www.ece.ntua.gr/en">School of Electrical and Computer Engineering</a></em><br>
						<a href="https://www.ntua.gr/en/">National Technical University of Athens</a> <span class="bull"></span> Greece
						<div class="collapse" id="col-teach-2007-iva">
							<div class="cv-detail just">
								<p>
									I assist in lectures and conduct a weekly laboratory, using Matlab. The laboratory is graded independently and counts for 50% of the course. The syllabus includes image sampling and quantization, two-dimensional transforms, image filtering, edge detection, enhancement and restoration, image and video coding and compression, and JPEG and MPEG standards. The laboratory includes additional topics, in particular Hough transform, corner and local feature detection, descriptor extraction, image retrieval, template matching and motion analysis. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-2007-ssms"></a>
						<div class="cv-year">
							2007
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Organizing Committee member</span>
				
							<a class="but acro" href="https://web.archive.org/web/2007/http://www.dcs.gla.ac.uk/ssms07/">SSMS&nbsp;2007</a>
						</div>
						<a href="https://web.archive.org/web/2007/http://www.dcs.gla.ac.uk/ssms07/"><em>Multimedia Semantics: Analysis, Annotation, Retrieval and Applications</em></a>
						<div class="cv-ref">
							Summer School <span class="bull"></span> Glasgow, UK <span class="bull"></span> July 15-21, 2007
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-2006-ssms"></a>
						<div class="cv-year">
							2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Organizing Committee member</span>
				
							<a class="but acro" href="https://web.archive.org/web/2006/http://mkg.iti.gr/ssms2006">SSMS&nbsp;2006</a>
						</div>
						<a href="https://web.archive.org/web/2006/http://mkg.iti.gr/ssms2006"><em>Multimedia Semantics: Analysis, Annotation, Retrieval and Applications</em></a>
						<div class="cv-ref">
							Summer School <span class="bull"></span> Chalkidiki, Greece <span class="bull"></span> September 4-8, 2006
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-2005-ss"></a>
						<div class="cv-year">
							2005-2014
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-teach-2005-ss">
							<i class="left-60 tog far fa-chevron-down"></i>
							Adjunct Professor
						</a>
							(407/80: 2005-2006)
							<span class="bull"></span>
							<a class="mr" href="https://web.archive.org/web/2014/http://cvsp.cs.ntua.gr/courses/systems/index.shtm">Signals and Systems</a>
				
							<a class="but acro" href="https://www.ntua.gr/en/">NTUA</a>
						</div>
						<em><a href="https://www.ece.ntua.gr/en">School of Electrical and Computer Engineering</a></em><br>
						<a href="https://www.ntua.gr/en/">National Technical University of Athens</a> <span class="bull"></span> Greece
						<div class="collapse" id="col-teach-2005-ss">
							<div class="cv-detail just">
								<p>
									I assist in lectures and prepare exercise material. The course syllabus includes signal and system properties, convolution, correlation, sampling, quantization, Fourier series, discrete and continuous time Fourier transforms, Laplace and Z transforms, time and frequency analysis of linear, time-invariant systems, stability, and discrete Fourier transform. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-2003-multimine"></a>
						<div class="cv-year">
							2003-2005
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Seminar Organizer</span>
				
							<a class="but acro" href="https://web.archive.org/web/2005/http://www.multimine.gr/">MultiMine</a>
						</div>
						<a href="https://web.archive.org/web/2005/http://www.multimine.gr/"><em>Multimedia Knowledge Discovery and Management</em></a>
						<div class="cv-ref">
							Research and Technology Training Network <span class="bull"></span> Athens, Greece
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-1996-analog"></a>
						<div class="cv-year">
							1996-1999
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						Assistant Lecturer
							<span class="bull"></span>
							<span class="mr">Analog Electronic Circuits</span>
				
							<a class="but acro" href="https://www.ntua.gr/en/">NTUA</a>
						</div>
						<em><a href="https://www.ece.ntua.gr/en">School of Electrical and Computer Engineering</a></em><br>
						<a href="https://www.ntua.gr/en/">National Technical University of Athens</a> <span class="bull"></span> Greece
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-1996-digital"></a>
						<div class="cv-year">
							1996-1998
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						Assistant Lecturer
							<span class="bull"></span>
							<span class="mr">Digital Image Processing</span>
				
							<a class="but acro" href="https://www.ntua.gr/en/">NTUA</a>
						</div>
						<em><a href="https://www.ece.ntua.gr/en">School of Electrical and Computer Engineering</a></em><br>
						<a href="https://www.ntua.gr/en/">National Technical University of Athens</a> <span class="bull"></span> Greece
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-1998-pascal"></a>
						<div class="cv-year">
							1998-2000
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						Lecturer
							<span class="bull"></span>
							<span class="mr">Pascal programming language</span>
				
						</div>
						<em>Department of Computer Science</em><br>
						Hellanion University of Portsmouth <span class="bull"></span> Athens, Greece
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="teach-1998-c"></a>
						<div class="cv-year">
							1998-2000
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						Lecturer
							<span class="bull"></span>
							<span class="mr">C programming language</span>
				
						</div>
						<em>Department of Computer Science</em><br>
						Hellanion University of Portsmouth <span class="bull"></span> Athens, Greece
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="talk"></a>
					<span class="mr">Invited talks</span>
					<i class="fal fa-podium"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2019-03"></a>
						<div class="cv-year">
							Mar&nbsp;2019
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-talk-2019-03">
							<i class="left-60 tog far fa-chevron-down"></i>
							Unsupervised and Semi-Supervised Learning on Manifolds
						</a>
						<a class="lnk" href="../data/cv/pdf/talk/2019.03.rennes-linkmedia.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						<em><a href="https://www-linkmedia.irisa.fr/">Linkmedia Team</a></em><br>
						<a href="http://www.inria.fr/en/centre/rennes">Inria Rennes-Bretagne Atlantique</a>
						<span class="bull"></span> France
						<div class="collapse" id="col-talk-2019-03">
							<div class="cv-detail just">
								<p>
									In this talk we discuss graph-based methods for image retrieval on manifolds, unsupervised representation learning and semi-supervised learning. We begin with a classic method for ranking data on manifolds that is adapted to descriptors of overlapping image regions for image retrieval, implemented by a sparse linear system solver. We show that this is equivalent to linear graph filtering, smoothing in particular, of a sparse signal in the frequency domain. We then apply this methodology for unsupervised network fine-tuning for retrieval, where positive and negative examples are found by disagreements between Euclidean and manifold similarities. Finally, we revisit classic graph-based transductive methods for semi-supervised learning and introduce an inductive framework, using label propagation to train a deep neural network. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2018-03"></a>
						<div class="cv-year">
							Mar&nbsp;2018
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-talk-2018-03">
							<i class="left-60 tog far fa-chevron-down"></i>
							Deep image retrieval and manifold learning
						</a>
						<a class="lnk" href="../data/cv/pdf/talk/2018.03.paris-safran.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						<a href="http://safran-group.com/">Safran Tech</a>
						<span class="bull"></span> Paris, France
						<div class="collapse" id="col-talk-2018-03">
							<div class="cv-detail just">
								<p>
									In this talk we discuss methods for visual representation learning from raw input data targeting image retrieval, that is, ranking according to visual similarity. The focus is on methods that do not require human annotation for supervision. We begin with background work on feature pooling from convolutional neural network activations, metric learning and algorithmic supervision. We then discuss a number of recent methods for efficient ranking on manifolds and their use for representation learning. These methods are based on a nearest neighbor graph of a given dataset and can be cast as linear graph filtering. Efficient solutions are found in the time or frequency domain, using simple ideas from numerical linear algebra. When applied to representation learning, these methods allow for improving the representation by just observing data. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2017-09"></a>
						<div class="cv-year">
							Sep&nbsp;2017
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<span class="mr">Deep learning and image retrieval</span>
						<a class="lnk" href="../data/cv/pdf/talk/2017.09.rennes-linkmedia-workshop.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						In <a href="https://web.archive.org/web/2018/http://people.rennes.inria.fr/Ahmet.Iscen/workshop/workshop.html">Deep Learning in Vision, Language, and Multimedia Workshop</a><br>
						<a href="http://www.inria.fr/en/centre/rennes">Inria Rennes-Bretagne Atlantique</a>
						<span class="bull"></span> France
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2017-05"></a>
						<div class="cv-year">
							May&nbsp;2017
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-talk-2017-05">
							<i class="left-60 tog far fa-chevron-down"></i>
							Searching over manifolds of image regions
						</a>
						<a class="lnk" href="../data/cv/pdf/talk/2017.05.menlo-park.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						<a href="https://research.fb.com/">Facebook Research</a>
						<span class="bull"></span> Menlo Park, CA, US
						<div class="collapse" id="col-talk-2017-05">
							<div class="cv-detail just">
								<p>
									Visual instance recognition has undergone a spectacular improvement by fine-tuning convolutional networks on properly designed image matching tasks. However, retrieving small objects is a common failure case that requires representing an image with several regions rather than a global descriptor. In this work, we discuss a principled query expansion mechanism on descriptors of overlapping image regions, based on a nearest neighbor graph constructed offline. We introduce a new way of handling unseen queries online, without adjusting the precomputed data. We rank images through a sparse linear system solver, yielding practical query times well below one second.
								</p>
								<p>
									While this result is encouraging, it also shows that the learned representations still lie on manifolds in a high dimensional space, and that exploring the manifolds online remains expensive. We therefore introduce an explicit embedding, reducing manifold search to Euclidean search followed by dot product similarity search. We show this is equivalent to linear graph filtering of a sparse signal in the frequency domain, and we introduce a scalable offline computation of an approximate Fourier basis of the graph. This reproduces or improves the results of online query expansion, at query times comparable to standard similarity search. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2016-03"></a>
						<div class="cv-year">
							Mar&nbsp;2016
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-talk-2016-03">
							<i class="left-60 tog far fa-chevron-down"></i>
							Large scale clustering and nearest neighbor search
						</a>
						<a class="lnk" href="../data/cv/pdf/talk/2016.03.prague-cmp-workshop.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						In <a href="http://cmp.felk.cvut.cz/cmp/events/colloquium-2016.03.31/">38th Pattern Recognition and Computer Vision Colloquium</a><br>
						<em><a href="http://cmp.felk.cvut.cz/">Center for Machine Perception (CMP)</a></em><br>
						<a href="https://www.cvut.cz/en">Czech Technical University (CVUT)</a>
						<span class="bull"></span> Prague, Czech Republic
						<div class="collapse" id="col-talk-2016-03">
							<div class="cv-detail just">
								<p>
									In this talk we discuss the role in approximate nearest neighbor search in large scale clustering, and applications in vision. We begin with a number of binary codes and product quantization extensions, highlighting the relation to nonlinear dimensionality reduction. We touch upon the deep connection between the two problems, involving distance maps in arbitrary dimensions. We then revisit recent advances in approximate k-means variants, and present a new one (IQ-means) that borrows their best ingredients. Combined with powerful deep learned representations, this method achieves clustering of a 100 million image collection on a single machine in less than one hour, while dynamically determining the number of clusters.
								</p>
								<p>
									Code for IQ-means is available on <a href="https://github.com/iavr/iqm">github</a>. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2016-01"></a>
						<div class="cv-year">
							Jan&nbsp;2016
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-talk-2016-01">
							<i class="left-60 tog far fa-chevron-down"></i>
							Geometry in shape decomposition, feature detection, matching, retrieval, clustering, and nearest neighbor search
						</a>
						<a class="lnk" href="../data/cv/pdf/talk/2016.01.heraklion-uoc.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						<em><a href="http://www.ics.forth.gr/index_main.php?l=e&n=4&id=467">Institute of Computer Science (ICS)</a></em><br>
						<a href="https://www.forth.gr/">Foundation for Research and Technology-Hellas (FORTH)</a>
						<span class="bull"></span> Heraklion, Greece
						<div class="collapse" id="col-talk-2016-01">
							<div class="cv-detail just">
								<p>
									In this talk we present a panoramic view of the geometry underpinning a number of vision problems, ranging from early vision to unsupervised mining in large image collections and beyond. Interplaying between continuous and discrete representations, geometry appears in different forms of duality, embeddings, and manifolds. We begin with planar shape decomposition as studied in psychophysics to model either occlusion or parts of recognition. Focusing on distance maps and the medial axis representation, we then generalize to natural images towards perceptual edge grouping and equivariant local feature detection.
								</p>
								<p>
									Adopting sets of local features and descriptors as an image representation, we then shift to visual instance search and recognition. We discuss a form of flexible spatial matching as mode seeking in the transformation space, a number of embeddings and match kernels in the descriptor space, and feature selection or aggregation in both. Acknowledging that the problem often boils down to nearest neighbor search in high-dimensional spaces, we consider a number of binary codes and product quantization extensions, highlighting the relation to nonlinear dimensionality reduction. Finally, we touch upon the deep connection between nearest neighbor search and clustering. In doing so, we revisit distance maps and medial representations, now in arbitrary dimensions. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2015-11"></a>
						<div class="cv-year">
							Nov&nbsp;2015
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<span class="mr">Clustering and nearest neighbor search</span>
						<a class="lnk" href="../data/cv/pdf/talk/2015.11.athens-erga.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						<em><a href="http://erga.di.uoa.gr/">Laboratory of Algebraic and Geometric Algorithms (ΕρΓΑ)</a></em><br>
						<a href="https://en.uoa.gr/">National and Kapodistrian University of Athens (NKUA)</a>
						<span class="bull"></span> Greece
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2015-06"></a>
						<div class="cv-year">
							Jun&nbsp;2015
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-talk-2015-06">
							<i class="left-60 tog far fa-chevron-down"></i>
							Geometry in feature detection, matching, search, and clustering
						</a>
						<a class="lnk" href="../data/cv/pdf/talk/2015.06.philadelphia-upenn.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						<em><a href="https://www.grasp.upenn.edu/">General Robotics, Automation, Sensing & Perception (GRASP) Laboratory</a></em><br>
						<a href="https://www.upenn.edu/">University of Pennsylvania</a>
						<span class="bull"></span> US
						<div class="collapse" id="col-talk-2015-06">
							<div class="cv-detail just">
								<p>
									In this talk we present a panoramic view of the geometry underpinning a number of vision problems, ranging from early vision to unsupervised mining in large image collections and beyond. Interplaying between continuous and discrete representations, geometry appears in different forms of duality, embeddings, and manifolds. We begin with planar shape decomposition as studied in psychophysics to model either occlusion or parts of recognition. Focusing on distance maps and the medial axis representation, we then generalize to natural images towards perceptual edge grouping and equivariant local feature detection.
								</p>
								<p>
									Adopting sets of local features and descriptors as an image representation, we then shift to visual instance search and recognition. We discuss a form of flexible spatial matching as mode seeking in the transformation space, a number of embeddings and match kernels in the descriptor space, and feature selection or aggregation in both. Acknowledging that the problem often boils down to nearest neighbor search in high-dimensional spaces, we consider a number of binary codes and product quantization extensions, highlighting the relation to nonlinear dimensionality reduction. Finally, we touch upon the deep connection between nearest neighbor search and clustering. In doing so, we revisit distance maps and medial representations, now in arbitrary dimensions. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2015-03"></a>
						<div class="cv-year">
							Mar&nbsp;2015
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-talk-2015-03">
							<i class="left-60 tog far fa-chevron-down"></i>
							Approximate nearest neighbor search: binary codes and vector quantization
						</a>
						<a class="lnk" href="../data/cv/pdf/talk/2015.03.athens-erga.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						<em><a href="http://erga.di.uoa.gr/">Laboratory of Algebraic and Geometric Algorithms (ΕρΓΑ)</a></em><br>
						<a href="https://en.uoa.gr/">National and Kapodistrian University of Athens (NKUA)</a>
						<span class="bull"></span> Greece
						<div class="collapse" id="col-talk-2015-03">
							<div class="cv-detail just">
								<p>
									Hashing is a popular solution to approximate nearest neighbor search, and appears in two variants: indexing data items in hash tables, or representing items by short binary codes and using these compact representations to approximate distances. We focus on the second approach, and more specifically on methods that learn codes from the data distribution.
								</p>
								<p>
									We then present methods based on vector quantization, which are a natural generalization. In particular, we discuss exhaustive and non-exhaustive variants of product quantization including recent optimizations, as well as additive quantization. Finally, we explore the opposite direction, that of using nearest neighbor search to speed up vector quantization itself. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2014-10"></a>
						<div class="cv-year">
							Oct&nbsp;2014
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-talk-2014-10">
							<i class="left-60 tog far fa-chevron-down"></i>
							Image retrieval, vector quantization and nearest neighbor search
						</a>
						<a class="lnk" href="../data/cv/pdf/talk/2014.10.rennes-texmex-workshop.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						In <a href="http://fire-id.gforge.inria.fr/microworkshop/">$\mu$-Workshop on Computer Vision</a><br>
						<em><a href="https://www.irisa.fr/texmex/index_en.php">TEXMEX Research Team</a></em><br>
						<a href="http://www.inria.fr/en/centre/rennes">Inria Rennes-Bretagne Atlantique</a>
						<span class="bull"></span> France
						<div class="collapse" id="col-talk-2014-10">
							<div class="cv-detail just">
								<p>
									The first part of this talk considers a family of metrics to compare images based on their local descriptors. It encompasses the VLAD descriptor and matching techniques such as Hamming embedding. Making the bridge between these approaches yields a match kernel that takes the best of existing techniques by combining an aggregation procedure with a selective match kernel.
								</p>
								<p>
									Since image search using either local or global descriptors boils down to approximate nearest neighbor search, the second part of this talk considers this problem, focusing on vector quantization methods. A recent method is presented whereby residuals over a coarse quantizer are used to locally optimize an individual product quantizer per cell. Non-exhaustive search strategies are discussed, including an inverted multi-index. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2012-04"></a>
						<div class="cv-year">
							Apr&nbsp;2012
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<span class="mr">Image matching and visual search</span>
						<a class="lnk" href="../data/cv/pdf/talk/2012.04.athens-madgik.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						<em><a href="http://www.madgik.di.uoa.gr/">Management of Data, Information and Knowledge (MADGIK) Group</a></em><br>
						<a href="https://en.uoa.gr/">National and Kapodistrian University of Athens (NKUA)</a>
						<span class="bull"></span> Greece
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2011-03"></a>
						<div class="cv-year">
							Mar&nbsp;2011
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-talk-2011-03">
							<i class="left-60 tog far fa-chevron-down"></i>
							Image matching and visual search: local features and geometry
						</a>
						<a class="lnk" href="../data/cv/pdf/talk/2011.03.bordeaux-labri.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						<em><a href="http://www.labri.fr/">Laboratoire Bordelais de Recherche en Informatique (LaBRI)</a></em><br>
						<a href="https://www.u-bordeaux.fr/">University of Bordeaux</a>
						<span class="bull"></span> France
						<div class="collapse" id="col-talk-2011-03">
							<div class="cv-detail just">
								<p>
									Methods based on local features have been very successful in visual search, especially when the objective is to identify near-identical objects or scenes under occlusion and varying viewpoint or lighting conditions. After a brief introduction to such methods, including bag-of-words models, sub-linear indexing and spatial matching, this talk focuses on recent research results related to local feature detection and the role of geometry, as well as a number of applications.
								</p>
								<p>
									In particular, we present methods based on image gradient and distance maps that are able to detect blob-like regions of arbitrary scale and shape, and their application to image matching. We then investigate the potential of embedding the spatial matching process within the index, so that it becomes sub-linear as well. We also report on an accelerated spatial matching method for re-ranking, that allows flexible matching of multiple surfaces.
								</p>
								<p>
									We then move to the more difficult problem of organizing large photo collections, and examine the use of sub-linear indexing in a mining process. Photos are automatically grouped wherever they depict the same scene; this structure is then exploited to increase the recall of the retrieval process. Working on community collections of geo-tagged photos depicting urban scenery, this approach is applied to automatic location and landmark recognition from a single photo. We also present our online application, VIRaL. Finally, we present our C++ template library ivl, that is used as infrastructure in our implementations.
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="talk-2006-09"></a>
						<div class="cv-year">
							Sep&nbsp;2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
						<span class="mr">Semantic multimedia content analysis</span>
						<a class="lnk" href="../data/cv/pdf/talk/2006.09.helsinki-ist-workshop.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						</div>
						In <a href="https://web.archive.org/web/2006/http://mkg.iti.gr/ist2006/">Workshop on Knowledge in Multimedia Content</a><br>
						<a href="https://web.archive.org/web/2006/http://europa.eu.int/information_society/istevent/2006/index_en.htm">IST Event 2006</a>
						<span class="bull"></span> Helsinki, Finland
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="phd"></a>
					<span class="mr">Ph.D. students / co-supervision</span>
					<i class="fal fa-user-graduate"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2020-tertikas"></a>
						<div class="cv-year">
							2020-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://users.uoa.gr/~ktertikas/">Konstantinos Tertikas</a>
						</div>
						Deep learning for 3D shape retrieval
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2020-venkataramanan"></a>
						<div class="cv-year">
							2020-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="https://shashankvkt.github.io/">Shashanka Venkataramanan</a>
						</div>
						Metric learning for instance- and category-level visual representations
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2020-psomas"></a>
						<div class="cv-year">
							2020-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://users.ntua.gr/psomasbill/">Bill Psomas</a>
						</div>
						Incremental learning
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2020-figueroa"></a>
						<div class="cv-year">
							2020-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Felipe Torres Figueroa
						</div>
						Learning discriminative representations to interpret image recognition models
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2020-engin"></a>
						<div class="cv-year">
							2020-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://people.rennes.inria.fr/Deniz.Engin/">Deniz Engin</a>
						</div>
						Semantic multimodal question answering
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2021-lifchitz"></a>
						<div class="cv-year">
							2018-2021
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="https://www.linkedin.com/in/yannlifchitz/en">Yann-Raphaël Lifchitz</a>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-phd-2021-lifchitz">
							<i class="left-60 tog far fa-chevron-down"></i>
							Representation and adaptation for few-shot image classification
						</a>
						<a class="lnk" href="../data/cv/pdf/phd/2021.lifchitz.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-phd-2021-lifchitz">
							<div class="cv-detail just">
								<p>
									Deep neural networks can be used to create highly accurate image classification models. One prerequisite is to have access to large-scale datasets for training. In the context of few-shot learning, the training set is limited to few images, so training from scratch is not feasible. Instead, a first training stage leverages a distinct set of abundant data to learn generic knowledge that can be transferred to few-shot tasks. A large part of the literature focuses on meta-learning, which consists in training strategies that apply to small sets of images.
								</p>
								<p>
									In this thesis, we rather follow a simpler approach. First, a task-independent representation function is learned on abundant data by solving a distinct task such as multi-class classification on a set of base classes. Then, the learned representation is combined with new data of novel classes to solve the few-shot task. In both stages, we introduce solutions that aim at leveraging available data as much as possible.
								</p>
								<p>
									In particular, for representation learning, we propose dense classification training, which for the first time studies local activations in the domain of few-shot learning. We also adapt the representation function to render it task-dependent, with a second learning phase using the few-shot set. The risk of overfitting during adaptation makes it a challenging task, which is not frequently performed outside of meta-learning. We propose two solutions for adaptation. By implanting, learning is limited to a few parameters; alternatively, by few-step adaptation, learning is limited to a few gradient updates.
								</p>
								<p>
									Additionally, we study alternative few-shot learning settings, in which access to data is modified. In transductive learning, multiple images need to be classified at the same time. In this context, we propose local propagation, a method that uses similarities between local representations of images to propagate class information, effectively leveraging the distribution the extra unlabeled data. We also introduce few-shot few-shot learning, a new setting, where only few or no in-domain data is accessible for representation learning. In this context, we take advantage of a representation obtained from a classifier that is pre-trained on a large-scale dataset of a different domain, which can still be adapted to the domain if data is available.
								</p>
								<p>
									In few-shot learning, because data is so scarce, we show that selecting relevant regions with an attention mechanism is important. In local propagation, this prevents propagation based on similarities of background regions. In few-shot-few-shot learning, it helps compensate for the domain gap. We propose two simple solutions that successfully fulfill this role. Finally, we apply our knowledge of few-shot learning on the specific problem of classifying aerial images. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2021-zhang"></a>
						<div class="cv-year">
							2017-2021
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Hanwei Zhang
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-phd-2021-zhang">
							<i class="left-60 tog far fa-chevron-down"></i>
							Deep learning in adversarial context
						</a>
						<a class="lnk" href="../data/cv/pdf/phd/2021.zhang.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-phd-2021-zhang">
							<div class="cv-detail just">
								<p>
									This thesis is about adversarial attacks and defenses in deep learning. We propose to improve the performance of adversarial attacks in terms of speed, distortion and invisibility.
								</p>
								<p>
									We contribute a definition of invisibility in terms of smoothness, which we integrate into the optimization of adversarial example generation. We achieve smooth adversarial perturbations of less distortion. To improve the efficiency of generating adversarial examples, we introduce an optimization algorithm called the Boundary Projection (BP) attack. BP first follows the gradient of the classification loss to until it finds an adversarial solution. It then searches along the class boundary to minimize the distortion. BP succeeds in generating adversarial examples with low-distortion very efficiently.
								</p>
								<p>
									We also study defenses against adversarial examples. We apply quantization on local patches of both images and intermediate layer features, using different kinds of codebooks that are either fixed or learned from training data. Experiments show that such patch replacement is efficient and robust against adversarial attacks, while it requires no network training. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2019-simeoni"></a>
						<div class="cv-year">
							2016-2019
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="https://osimeoni.github.io">Oriane Siméoni</a>
							<div class="cv-ref">
								now Research Scientist at
								<a href="https://www.valeo.com/en/valeo-ai/">Valeo</a>, France
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-phd-2019-simeoni">
							<i class="left-60 tog far fa-chevron-down"></i>
							Robust image representation for classification, retrieval and object discovery
						</a>
						<a class="lnk" href="../data/cv/pdf/phd/2019.simeoni.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-phd-2019-simeoni">
							<div class="cv-detail just">
								<p>
									Neural network representations have proved to be relevant for many computer vision tasks such as image classification, object detection, segmentation or instance-level image retrieval, but require a large number of labeled data. In this thesis, we propose solutions to extract the most information with the least supervision.
								</p>
								<p>
									Focusing on the classification task first, we examine active learning in the context of deep learning and show that combining it with semi-supervised and unsupervised learning greatly boosts results. We then investigate the image retrieval task, and in particular we exploit the spatial localization information available "for free" in CNN feature maps. We first propose to represent an image by a collection of affine local features detected within activation maps, which are memory-efficient and robust enough to perform spatial matching. Then, extracting information from feature maps, we discover objects of interest in images of a dataset and gather their representations in a nearest neighbor graph. Using the centrality measure on the graph, we construct a saliency map per image, which focuses on repeating objects and allows us to compute a global representation, suppressing background clutter. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2013-papanelopoulos"></a>
						<div class="cv-year">
							2013-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Nikos Papanelopoulos
							<div class="cv-ref">
								PhD paused in 2016
							</div>
						</div>
						Visual sketch retrieval
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2014-kalantidis"></a>
						<div class="cv-year">
							2009-2014
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://www.skamalas.com/">Yannis Kalantidis</a>
							<div class="cv-ref">
								now Research Scientist at
								<a href="https://europe.naverlabs.com/">Naver Labs Europe</a>, France
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-phd-2014-kalantidis">
							<i class="left-60 tog far fa-chevron-down"></i>
							Web-scale image search, clustering and localization
						</a>
						<a class="lnk" href="../data/cv/pdf/phd/2014.kalantidis.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-phd-2014-kalantidis">
							<div class="cv-detail just">
								<p>
									New applications that exploit the huge data volume in community photo collections are emerging every day and visual image search is therefore becoming increasingly important. In this thesis we propose clustering- and nearest neighbor-based improvements for visual image search. Clustering is either performed on feature space or on image space, i.e. on high-dimensional vector spaces or metric spaces, respectively.
								</p>
								<p>
									We first introduce a clustering method that combines the flexibility of Gaussian mixtures with the scaling properties needed to construct visual vocabularies for image retrieval. It is a variant of expectation-maximization that can converge rapidly while dynamically estimating the number of components. We employ approximate nearest neighbor search to speed-up the E-step and exploit its iterative nature to make search incremental, boosting both speed and precision. We achieve superior performance in large scale retrieval, being as fast as the best known approximate k-means algorithm.
								</p>
								<p>
									We then present our locally optimized product quantization scheme, an approximate nearest neighbor search method that locally optimizes product quantizers per cell, after clustering the data in the original space. When combined with a multi-index, its performance is unprecedented and sets the new state-of-the-art in a billion scale dataset. At the same time, our approach enjoys query times in the order of a few milliseconds, an it becomes comparable in terms of speed even to hashing approaches.
								</p>
								<p>
									We next focus on large community photo collections. Most applications for such collections focus on popular subsets, e.g. images containing landmarks or associated to Wikipedia articles. In this thesis we are concerned with the problem of accurately finding the location where a photo is taken without needing any metadata, that is, solely by its visual content. We also recognize landmarks where applicable, automatically linking them to Wikipedia. We show that the time is right for automating the geo-tagging process, and we show how this can work at large scale. In doing so, we do exploit redundancy of content in popular locations--but unlike most existing solutions, we do not restrict to landmarks. In other words, we can compactly represent the visual content of all thousands of images depicting e.g. the Parthenon and still retrieve any single, isolated, non-landmark image like a house or a graffiti on a wall.
								</p>
								<p>
									Starting from an existing, geo-tagged dataset, we cluster images into sets of different views of the the same scene. This is a very efficient, scalable, and fully automated mining process. We then align all views in a set to one reference image and construct a 2D scene map. Our indexing scheme operates directly on scene maps. We evaluate our solution on a challenging one million urban image dataset and provide public access to our service through our online application, VIRaL.
								</p>
								<p>
									The thesis concludes with two chapters. The first is a summary of other approaches for visual search and applications, like geometry indexing, logo detection and clothing recognition, while the second presents conclusions and possible future directions. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2016-varytimidis"></a>
						<div class="cv-year">
							2008-2016
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://image.ntua.gr/iva/chrisvar/">Christos Varytimidis</a>
							<div class="cv-ref">
								now Senior Machine Learning Engineer at
								<a href="https://www.workable.com/">Workable</a>, Greece
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-phd-2016-varytimidis">
							<i class="left-60 tog far fa-chevron-down"></i>
							Local feature detection for visual information retrieval
						</a>
						<a class="lnk" href="../data/cv/pdf/phd/2016.varytimidis.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-phd-2016-varytimidis">
							<div class="cv-detail just">
								<p>
									Low-level image analysis offers an intermediate image representation that is used by high-level computer vision algorithms (e.g. object detection and recognition, image and video retrieval, image matching). Local features extracted as regions of interest, or spatio-temporal interest points extracted from videos, combined with local descriptors, as well as global descriptors, offer a compact representation of visual information. Despite the fact that many local feature detectors have been proposed recently, this field of research is still open to new methods, as new and more complex application fields are introduced. Recently, the interest of the computer vision community has focused on deep neural networks, based on results in image classification tasks.
								</p>
								<p>
									We propose an new local feature detector, based on geometric constructions. In particular, we propose using α-shapes to describe the shape of a set of points sampled on an image. Given the point set, α-shapes describe image objects in different scales and with different level of detail. For image sampling, we propose two different approaches: sampling on image edges and sampling using error diffusion. For sampling image edges, we propose a method that exploits the local affine shape in order to adapt sampling density, as well as a baseline method that uses fixed density sampling. We also propose sampling using error diffusion on two different functions of image intensity. The first one is based on first-order derivatives of image intensity (gradient strength), while the second one is based on second-order derivatives (Hessian response).
								</p>
								<p>
									We use different triangulations of the samples and different α-shapes, and propose the anisotropically weighted α-shapes that exploit the local shape of each simplex of the triangulation. For selecting regions of interest, we propose different importance measures for the connected components of α-shapes. We qualitatively and quantitatively evaluate the proposed local feature extraction algorithm, under all proposed variations for each algorithm step. Our detector extracts a relatively small number of features from image regions that correspond to highly repeatable object parts. Its performance exceeds the state-of-the-art in most cases.
								</p>
								<p>
									We also propose an efficient method for describing video clips, using deep neural networks. We segment videos in shots, using a novel method that exploits a global "objectness" measure. For describing video frames, we exploit neural networks feature maps, and then aggregate the responses to create a single descriptor for the video shot. We evaluate the proposed method on a surgical video retrieval experiment, where other methods based on local features are outperformed. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2013-tolias"></a>
						<div class="cv-year">
							2008-2013
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://cmp.felk.cvut.cz/~toliageo/">Giorgos Tolias</a>
							<div class="cv-ref">
								now Assistant Professor at
								<a href="http://cmp.felk.cvut.cz/">Center for Machine Perception</a>, Czech Republic
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-phd-2013-tolias">
							<i class="left-60 tog far fa-chevron-down"></i>
							Large scale object-based image retrieval
						</a>
						<a class="lnk" href="../data/cv/pdf/phd/2013.tolias.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-phd-2013-tolias">
							<div class="cv-detail just">
								<p>
									A wide range of properties and assumptions determine the most appropriate spatial matching model for an application, e.g. recognition, detection, registration, or large scale image retrieval. Most notably, these include discriminative power, geometric invariance, rigidity constraints, mapping constraints, assumptions made on the underlying features or descriptors and, of course, computational complexity.
								</p>
								<p>
									We present a new approach to image indexing and retrieval, which integrates appearance with global image geometry in the indexing process, while enjoying robustness against viewpoint change, photometric variations, occlusion, and background clutter. We exploit shape parameters of local features to estimate image alignment via a single correspondence. Then, for each feature, we construct a sparse spatial map of all remaining features, encoding their normalized position and appearance, typically vector quantized to visual word. An image is represented by a collection of such feature maps and RANSAC-like matching is reduced to a number of set intersections. We use min-wise independent permutations and derive a similarity measure for feature map collections. In addition to random selection, we have further exploited multiple view matching for feature selection. This allows us to scale geometry indexing up to 1M images. We then exploit sparseness to build an inverted file whereby the retrieval process is sub-linear in the total number of images, ideally linear in the number of relevant ones.
								</p>
								<p>
									We further present a very simple model inspired by Hough voting in the transformation space, where votes arise from single feature correspondences. A relaxed matching process allows for multiple matching surfaces or non-rigid objects under one-to-one mapping, yet is linear in the number of correspondences. We apply it to geometry re-ranking in a search engine, yielding superior performance with the same space requirements but a dramatic speed-up compared to the state of the art.
								</p>
								<p>
									We further extend and use our relaxed spatial matching for self-matching and symmetry detection. We assume that features participating in symmetric and repeating structures have higher probability to be matched between different views of the same object. Information from geometric self-matching and matching of the image with its mirrored counterpart is used for feature selection of single images.
								</p>
								<p>
									In contrast to the previous methods that we discussed or proposed, which all use only visual word information to perform feature matching, we further exploit the Hamming (HE) Embedding technique, which further use descriptor information. HE employs each feature with visual word and a binary signature which allows more precise feature matching. We develop a novel query expansion strategy which is aligned with the HE representation. We achieve to improve performance even without geometry matching, in contrast to previous query expansion methods, along with low query times. We finally show that combining our scheme with geometry matching can further boost performance and outperform state of the art methods. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2009-spyrou"></a>
						<div class="cv-year">
							2005-2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://image.ntua.gr/iva/espyrou/">Evaggelos Spyrou</a>
							<div class="cv-ref">
								now Assistant Professor at
								<a href="www.uth.gr/en/">University of Thessaly</a>, Greece
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-phd-2009-spyrou">
							<i class="left-60 tog far fa-chevron-down"></i>
							Semantic search of audiovisual content using knowledge
						</a>
						<a class="lnk" href="../data/cv/pdf/phd/2009.spyrou.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-phd-2009-spyrou">
							<div class="cv-detail just">
								<p>
									The growth of production and demand for digital audiovisual content during the last few decades has been overwhelming. To fulfill the needs of its users, this multimedia content should be annotated, commented and classified into appropriate semantic classes, in order to facilitate search and access to it. This thesis deals with the analysis of multimedia content and faces a few of the most important research problems in the field of multimedia analysis. More specifically, it faces problems such as image classification, image region classification and detection of concepts in images. To achieve this, certain techniques that exploit directly and indirectly the knowledge of a domain are proposed and evaluated. This knowledge is encoded either in the form of appropriate ontologies, or by modeling the context of the images and their regions, or by applying machine learning techniques. It emphasizes on the use of the bag-of-words model in order to describe the visual features of images. Finally, the techniques applied in high-level concept detection in images are extended in order to be applied to the problems of image retrieval and video summarization. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2009-athanasiadis"></a>
						<div class="cv-year">
							2004-2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://image.ntua.gr/iva/thanos/">Thanos Athanasiadis</a>
							<div class="cv-ref">
								now Machine Learning Engineer at
								<a href="https://www.tadaweb.com/">Tadaweb</a>, Luxemburg
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-phd-2009-athanasiadis">
							<i class="left-60 tog far fa-chevron-down"></i>
							Knowledge technologies and access to audiovisual information
						</a>
						<a class="lnk" href="../data/cv/pdf/phd/2009.athanasiadis.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-phd-2009-athanasiadis">
							<div class="cv-detail just">
								<p>
									The main research area of this thesis, in a broad sense, is the integration of knowledge technologies into the analysis and description of multimedia. Knowledge technologies can aid computer vision tasks towards the improvement of the understanding of visual content, by exploiting a priori knowledge in algorithms of semantic image and video analysis. More specifically, we examine the problem of image and video segmentation and we propose novel techniques for the detection, extraction, recognition and tracking of objects, based on semantic and visual criteria. We propose a semantic segmentation approach, which enhances region growing algorithms with semantic characteristics, in order to deal with problems that raise from the shortcoming of describing semantic entities by visual characteristics exclusively. Moreover, we propose a structured knowledge framework, which we call visual logics, based on description logics and their fuzzy extensions, to link visual data with concepts that form the vocabulary of a domain. We use a set of axioms and a reasoning engine to infer possible semantic interpretation of parts or the whole of an image. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2008-rapantzikos"></a>
						<div class="cv-year">
							2003-2008
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="https://www.linkedin.com/in/rapantzikos/">Konstantinos Rapantzikos</a>
							<div class="cv-ref">
								now VP of Data Science at
								<a href="https://www.workable.com/">Workable</a>, Greece
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-phd-2008-rapantzikos">
							<i class="left-60 tog far fa-chevron-down"></i>
							Visual saliency models for the analysis of static and moving images
						</a>
						<a class="lnk" href="../data/cv/pdf/phd/2008.rapantzikos.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-phd-2008-rapantzikos">
							<div class="cv-detail just">
								<p>
									Although human vision appears to be easy and unconscious, there exist complex neural mechanisms in primary visual cortex that form the pre-attentive component of the Human Visual System (HVS) and lead to visual awareness. Considerable research has been carried out into the attention mechanisms of the HVS and computational models have been developed and employed to common computer vision problems. Most of the models simulate the bottom-up mechanism of the HVS and their major goal is to filter out redundant visual information and detect/enhance the most salient parts of the input. The Human Visual System (HVS) has the ability to fixate quickly on the most informative (salient) regions of a scene and therefore reduce the inherent visual uncertainty. Computational visual attention (VA) schemes have been proposed to account for this important characteristic of the HVS. The dissertation studies and expands the field of computational visual attention methods, proposes novel models both for spatial (images) and spatio-temporal (video sequences) analysis and evaluates both qualitatively and quantitatively in a variety of relevant applications. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2008-mylonas"></a>
						<div class="cv-year">
							2003-2008
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://image.ntua.gr/~fmylonas/">Phivos Mylonas</a>
							<div class="cv-ref">
								now Associate Professor at
								<a href="https://ionio.gr/en/">Ionian University</a>, Greece
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-phd-2008-mylonas">
							<i class="left-60 tog far fa-chevron-down"></i>
							Adaptive multimedia content access based on context and user profiles
						</a>
						<a class="lnk" href="../data/cv/pdf/phd/2008.mylonas.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-phd-2008-mylonas">
							<div class="cv-detail just">
								<p>
									The main research objective of this Thesis is to tackle issues related to multimedia content processing, search and retrieval, under the prism of context, as the latter is expressed in the fields of knowledge adaptation and information access. More specifically, the main research motivation was caused by two major research fields: (i) multimedia content personalization and (ii) multimedia content analysis based on visual context. It tackles issues such as data mining, thematic categorization of multimedia documents, multimedia personalization, retrieval and ranking of personalized multimedia documents, knowledge-assisted analysis optimization through visual context exploitation, mid-level visual analysis and context utilization, contextual image classification problems, etc. Towards this direction, it presents research results and indicative applications, in order to facilitate the proposed interpretation. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="phd-2005-wallace"></a>
						<div class="cv-year">
							2001-2005
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://gav.uop.gr/wallace/">Manolis Wallace</a>
							<div class="cv-ref">
								now Assistant Professor at
								<a href="https://www.uop.gr/en/">University of Peloponnese</a>, Greece
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-phd-2005-wallace">
							<i class="left-60 tog far fa-chevron-down"></i>
							Intelligent knowledge-based systems in uncertain environments
						</a>
						<a class="lnk" href="../data/cv/pdf/phd/2005.wallace.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-phd-2005-wallace">
							<div class="cv-detail just">
								<p>
									Uncertainty has gradually attained acceptance and a very distinct role in scientific thought as well as in the scientific view of the world. As far as intelligent knowledge based systems are concerned, uncertainty is present at all levels of their operation and its role is determinant of their effectiveness. In this thesis we propose a series of solutions to uncertainty related problems. In their turn, these solutions provide for further thought and progress in a series of directions.
								</p>
								<p>
									In the first part of the thesis, which is also the lengthiest, the emphasis is on the semantics. In this framework, the important problems to consider are those of modeling real world concepts thus constructing a formal knowledge base and of exploiting the information contained in this knowledge base in practical applications, given its size. In this direction, chapter 2 proposes the utilization of fuzzy relations for the representation of knowledge and explains how this knowledge can be used in order to automatically extract the context. Chapters 3 and 4 focus on the size of this knowledge and provide computational models for its efficient handling. Chapters 5 and 6 deal with the intelligent utilization of such knowledge in the framework if information retrieval.
								</p>
								<p>
									In the second part of the thesis we move on to a level between concepts and numeric data. Thus, chapter 7 explains how we can use high level linguistic information in order to handle uncertain low level numerical data. Focus is both on the uncertainty within the low level data and on the flexibility required in order for the high level information to provide for an adequate description of the real world.
								</p>
								<p>
									In the third and last part of the thesis we work solely with numerical data. Chapters 8 and 9 deal with the automated analysis of data for the generation of neural models that are able to map the structure of the data, while chapter 10 moves on to the processing of these models in order to automatically extract higher level information from the available numerical data.
								</p>
								<p>
									Chapter 11 summarizes conclusions drawn from this thesis and refers to directions of possible further work that come out of this work. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="msc"></a>
					<span class="mr">Diploma Thesis/M.Sc. students / co-supervision</span>
					<i class="fal fa-user-graduate"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2021-bellos"></a>
						<div class="cv-year">
							2020-2021
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Phillip Bellos
							<div class="cv-ref">
								now PhD Student at
								<a href="https://www.ntnu.edu/">Norwegian University of Science and Technology</a>, Norway
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2021-bellos">
							<i class="left-60 tog far fa-chevron-down"></i>
							Iterative Label Cleaning for Semi-Supervised Learning
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2021.bellos.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2021-bellos">
							<div class="cv-detail just">
								<p>
									Deep neural networks have become the de facto model for computer vision applications. Their success is partially attributable to their scalability, i.e., the empirical observation that training them on larger datasets produces better performance. Deep networks often achieve their strong performance through supervised learning, which requires a labeled dataset. The performance benefit conferred by the use of a larger dataset can therefore come at a significant cost, since labeling data often requires human labor. This cost can be extraordinary when labeling must be done by an expert.
								</p>
								<p>
									A powerful approach for training models on a large amount of data without requiring a large amount of labels is semi-supervised learning (SSL). SSL mitigates the requirement for labeled data by providing a means of leveraging unlabeled data. Since unlabeled data can often be obtained with minimal human labor, any performance boost conferred by SSL often comes with low cost. This has led to a plethora of SSL methods that are designed for deep networks.
								</p>
								<p>
									In this thesis, we propose two methods that combine successful ideas in problems related to our task at hand. In particular, we propose CleanMatch and WeightMatch, two new semi-supervised learning methods that unify dominant approaches and address their limitations. CleanMatch consists of two stages: (1) iterative selection of the most confident pseudo-labels provided by a combination of consistency regularization and pseudo-labeling, following FixMatch; and (2) augmentation of the labeled set with the selected examples of the first stage and semi-supervised training, using FixMatch on the augmented dataset. WeightMatch estimates a weight reflecting the confidence of each labeled example, forcing the model to rely more on the confident ones during training.
								</p>
								<p>
									Our methods achieve state-of-the-art performance on multiple datasets. They achieve substantial accuracy improvements on label-scarce versions of CIFAR-10, SVHN and CIFAR-100. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2020-psomas"></a>
						<div class="cv-year">
							2019-2020
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://users.ntua.gr/psomasbill/">Bill Psomas</a>
							<div class="cv-ref">
								now PhD Student at
								<a href="https://www.ntua.gr/en/">National Technical University of Athens</a>, Greece
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2020-psomas">
							<i class="left-60 tog far fa-chevron-down"></i>
							Metric Learning: A Deep Dive
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2020.psomas.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2020-psomas">
							<div class="cv-detail just">
								<p>
									The objective of metric learning is to learn a distance metric that decreases the distance between similar objects and increases the distance between dissimilar ones. Similarity and dissimilarity can be subjective and thus some supervision is needed to define them. Learning a distance metric can be useful for many tasks, such as classification, retrieval and clustering. The classification and retrieval tasks can be reduced to class-level and instance-level nearest neighbor tasks respectively, while the clustering task can be made easier given the similarity matrix.
								</p>
								<p>
									Before deep learning, metric learning approaches were based either on linear transformations using the Mahalanobis or/and Euclidean distance, or on non-linear transformations using kernel-based methods. Both of them, however, had limitations. Linear transformations had a limited ability to capture nonlinear feature structure. Non-linear transformations performed better, but often suffered from overfitting. Both methods were limited by their ability to process raw data and thus needed feature engineering.
								</p>
								<p>
									With the remarkable success of convolutional neural networks, deep metric Learning was introduced. Neural networks are discriminatively trained to learn the non-linear mapping from raw input data to a lower dimensional embedding. This is usually done in a supervised way, where embeddings with the same class label are pushed closer and embeddings with different class labels are pulled apart. The training process involves minimizing a loss function having exactly these properties. The advantage of deep metric learning is that it jointly extracts the features and learns the embedding.
								</p>
								<p>
									The contribution of this work is threefold. First, we conduct extensive experiments using the most commonly used architectures (GoogLeNet, BNInception, ResNet50) on the most commonly used datasets (CUB200-2011, CARS196, Stanford Online Products) using 10 different loss functions (Contrastive, Triplet, LiftedStructure, NPair, ProxyNCA, ArcFace, Margin, MultiSimilarity, SoftTriple, ProxyAnchor) and four different embedding sizes (64, 128, 512, 1024). We make an ablation study and draw important conclusions using the results, revealing significant flaws in the evaluation and little true progress over time. Second, we introduce and propose a new setup for training using a fixed validation set. We conduct experiments using this split, as well as a 10-fold cross validation. Our setup seems to balance perfectly between computational complexity and retrieval quality. Finally, we design, implement and experiment with a new loss function that is on a par with the state-of-the-art. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2020-neitthoffer"></a>
						<div class="cv-year">
							2019-2020
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Timothée Neitthoffer
							<div class="cv-ref">
								now PhD Student at
								<a href="https://www.univ-rennes1.fr/en">University of Rennes 1</a>, France
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2020-neitthoffer">
							<i class="left-60 tog far fa-chevron-down"></i>
							Neural Architecture Growing, Pruning and Search
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2020.neitthoffer.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2020-neitthoffer">
							<div class="cv-detail just">
								<p>
									The goal of neural architecture search is to automatically find the optimal network architecture, that is, the optimal succession of layers and how they are connected to each other to solve a particular learning task (for instance, image classification). This is a combinatorial optimization problem and finding the optimal set of connections over all possible combinations is intractable.
								</p>
								<p>
									We address this problem by combining ideas from different fields. We define a "fully-dense" network where every layer has access to all previous ones and contains all possible connections between layers. This super-network contains different possible subsequences of layers by considering the possibility to skip unnecessary connections. We select the most important ones using a pruning criterion that removes the unnecessary connections. This way, the optimal architecture can be found within the super-network.
								</p>
								<p>
									However, the number of connections in the super-network is quadratic in the number of layers. Training the super-network is not practical when it is very deep. To alleviate this problem, we devise a greedy algorithm, growing the super-network a few layers at a time, training it and pruning its connections at each iteration. This way, the number of connections at each iteration is linear in the network depth. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2016-kervadec"></a>
						<div class="cv-year">
							2015-2016
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="https://scholar.google.com/citations?user=yeFGhfgAAAAJ">Hoel Kervadec</a>
							<div class="cv-ref">
								now PhD Student at
								<a href="https://www.etsmtl.ca/en/">ÉTS Montréal</a>, Canada
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2016-kervadec">
							<i class="left-60 tog far fa-chevron-down"></i>
							Deep Hough Networks for Object Detection
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2016.kervadec.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2016-kervadec">
							<div class="cv-detail just">
								<p>
									Our goal in this work has been to investigate new methods for object detection combining already existing tools and algorithms, Convolutional Neural Networks (CNN) and the Hough transform. CNNs are a standard tool in deep learning for image classification, and are increasingly used for object detection as well. The Hough transform is a category of algorithms that uses votes to predict where potential objects could be. We start with some background to help to understand this report, and discuss related work. Then, we present our work, step by step. Starting with a standard neural network architecture, we gradually add new functions, layers that would get us closer to our goal. We first retrain parts of the network to fit our new training data. Then, we change the network so it would consider subparts of images and not images as a whole. Next, we add layers to limit false positive and duplicates during detection. Finally, we create a end-to-end method to train the network. Since this is still ongoing work, we discuss methods that can be tested in the future. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2015-mitsis"></a>
						<div class="cv-year">
							2014-2015
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="https://www.linkedin.com/in/giorgos-mitsis-351a76104/">Giorgos Mitsis</a>
							<div class="cv-ref">
								now PhD Student at
								<a href="https://www.ntua.gr/en/">National Technical University of Athens</a>, Greece
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2015-mitsis">
							<i class="left-60 tog far fa-chevron-down"></i>
							Object Proposals for Rapid Object Detection
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2015.mitsis.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2015-mitsis">
							<div class="cv-detail just">
								<p>
									Object proposals is a relatively new problem which appeared due to the complexity of modern object detectors and their high execution time. The purpose of object proposal algorithms is the high speed class-agnostic detection of all objects in the image. The proposals are then passed to the object detectors so that they avoid the exhaustive search of the image using the sliding window approach. This way, the time needed to detect objects is drastically reduced which enables them to use more complex and effective algorithms. Modern object detectors use object proposals.
								</p>
								<p>
									In our thesis we present most modern methods for the extraction of object proposals and we propose a new method, Segment Boxes. This method uses segmentation of the image and by using the resulting segments we score windows inside the image based on the possibility that they contain objects. We try to encapsulate good ideas of other methods as well as some of our own to achieve best results, so we end up with several variants of our method.
								</p>
								<p>
									We compare those different approaches and the best ones are compared with the state-of-the-art methods, using the appropriate metrics, on images from datasets PASCAL VOC07 and ImageNet2013. We then use our proposals with a modern object detector which uses deep learning and convolutional neural networks, Fast R-CNN, and we compare again our results with those of other methods, this time on the problem of object detection. Our results are competitive with those of the state-of-the-art methods, and in some cases they even exceed them, while achieving low execution time (one of our approaches runs on 0.3 seconds per image). Our goal is to examine the potential of segmentation on the problem of object proposals. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2015-chatzipanos"></a>
						<div class="cv-year">
							2014-2015
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Vasileios Chatzipanos
							<div class="cv-ref">
								now Software Engineer at
								<a href="https://www.crunchrapps.com/">Crunchr</a>, The Netherlands
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2015-chatzipanos">
							<i class="left-60 tog far fa-chevron-down"></i>
							Compact Representations for Image Retrieval
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2015.chatzipanos.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2015-chatzipanos">
							<div class="cv-detail just">
								<p>
									This thesis addresses the problem of content based large scale image retrieval (CBIR). We study the algorithms and methods that are being used to produce compact image vector representations and primarily the VLAD image representation. We showcase the main algorithm used to produce the VLAD vector and known methods to improve it. Finally, we examine novel image representation vectors based on VLAD and a normalization scheme that can be used for further improvement. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2014-papadopoulos"></a>
						<div class="cv-year">
							2013-2014
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Athanasios Papadopoulos
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2014-papadopoulos">
							<i class="left-60 tog far fa-chevron-down"></i>
							Geometric Descriptor Aggregation for Image Retrieval and Classification
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2014.papadopoulos.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2014-papadopoulos">
							<div class="cv-detail just">
								<p>
									We propose a new method for the vector representation of an image which is based on aggregation of image descriptors while exploiting their spatial information. Our method, Spatial Pyramid with Vectors of Locally Aggregated Descriptors (SP-VLAD), was designed for the problem of image retrieval in order to achieve high accuracy and efficiency, with low memory requirements. SP-VLAD is based on the ideas of two other methods, Spatial Pyramid Matching (SPM) and Vector of Locally Aggregated Descriptors (VLAD). Specifically, it combines the idea of spatial pyramid with the VLAD descriptor vectors. The SP-VLAD method achieves high accuracy and significantly outperforms SPM and VLAD methods. The promising results led us to apply our method to the problem of image classification as well; exceeding the classification rate of SPM and VLAD methods on all databases which were used. The excellent results of our method were achieved with low memory usage after the dimension reduction of the descriptor vectors with the PCA method which resulted to vectors of 64 or 128 dimensions. We also created the dataset Flowers 15 for the needs of our research in order to be able to test the SP-VLAD method upon images of flowering plants. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2014-perakis"></a>
						<div class="cv-year">
							2013-2014
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Georgios Perakis
							<div class="cv-ref">
								now Key Account Manager at
								<a href="https://www.inos-automation.de/">inos Automation</a>, Germany
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2014-perakis">
							<i class="left-60 tog far fa-chevron-down"></i>
							License Plate Detection and Recognition Using Local Features
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2014.perakis.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2014-perakis">
							<div class="cv-detail just">
								<p>
									License plate recognition is an integral part of intelligent traffic control systems, with ever more applications. The goal of this diploma thesis is the creation of a prototype system for license plate detection and recognition with the use of local descriptors of the image. The most important methods so far for both parts of the problem are described. Problems that arose during the implementation of the method are presented, as well as the chosen solutions against them. Furthermore, the need to create a global data set for license plate recognition is noted, since without it there cannot be a reliable comparison among the suggested solutions and selection of the best. For the data set of Greek license plates that was available, the detection rate was 94% and the recognition rate 32.3%, with the use of a free platform. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2012-arvanitis"></a>
						<div class="cv-year">
							2011-2012
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Christos Arvanitis
							<div class="cv-ref">
								now DevOps Engineer at
								<a href="https://www.impactechs.com/">Impact Tech</a>, Cyprus
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2012-arvanitis">
							<i class="left-60 tog far fa-chevron-down"></i>
							Computer Vision Methods for Augmented Reality
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2012.arvanitis.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2012-arvanitis">
							<div class="cv-detail just">
								<p>
									Augmented Reality is a growing area in the recent years, in the field of Virtual Reality. A system of Augmented Reality supplements the real world with virtual graphical models, creating the illusion of coexistence between real and virtual world. This process requires accurate camera pose estimation based on computer vision methods. In the framework of this thesis, we aim to study the camera pose estimation methods based on the detection of local features in successive frames, without prior knowledge of the environment. Furthermore we present an implementation of an Augmented Reality application. Epipolar constraints are used for the camera pose estimation. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2012-delvinioti"></a>
						<div class="cv-year">
							2011-2012
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="https://www.linkedin.com/in/agni-delvinioti/">Agni Delvinioti</a>
							<div class="cv-ref">
								now Data Scientist at
								<a href="https://www.fsitaliane.it/">Ferrovie dello Stato Italiane</a>, Italy
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2012-delvinioti">
							<i class="left-60 tog far fa-chevron-down"></i>
							Image Classification by Spatial Matching and Indexing
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2012.delvinioti.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2012-delvinioti">
							<div class="cv-detail just">
								<p>
									In the framework of this Diploma thesis we introduce a new image categorization method, which integrates spatial matching and indexing in the classification process. Spatial matching is based on Hough pyramid matching (HPM); indexing is based on an inverted file structure as in image retrieval; and classification is carried out with a multi-class support vector machine (SVM) classifier. We use HPM as an image similarity measure and we show that under reasonable assumptions it is a Mercer kernel. We do so by explicitly expressing it as an inner product in a high dimensional space where images lie given an appropriate quantized representation of their local features and descriptors. We then use this kernel for SVM training instead of a linear kernel, which is a typical choice under the bag of words (BoW) model. It is the first time that a kernel function takes spatial configuration into account while being invariant to translation, scale and rotation. In most cases, artificial perturbations are the only way to achieve geometric invariance, with an exponential increase of training time.
								</p>
								<p>
									We train one binary SVM classifier for each category following an one-versus-the -rest strategy and then combine individual classifiers into one multi-class classifier. Comparing to nearest-neighbor classifier using e.g. image retrieval methods, we exploit the sparse representation of SVMs: at classification time, the query image is matched via HPM against the chosen support vectors only. However, matching need not be exhaustive. Support vectors are indexed into an inverted file, and HPM may be applied only to a small subset that is top-ranking according to any scalar similarity measure, e.g. based on BoW. The method therefore easily applies to large scale classification, while training for unseen classes does not require re-training for existing ones.
								</p>
								<p>
									Due to the nature of local features and their use in invariant matching, the method is most appropriate for specific object recognition. We apply it to landmark recognition, conducting experiments on our own dataset, constructed from the World cities dataset via a semi-automatic process that combines visual and geographical clustering. We compare to a baseline classifier using a BoW representation and achieve more than a twofold increase in accuracy on experiments of up to 68 landmarks. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2012-leonardos"></a>
						<div class="cv-year">
							2011-2012
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="https://www.grasp.upenn.edu/people/spyridon-leonardos">Spyros Leonardos</a>
							<div class="cv-ref">
								now PhD Student at
								<a href="https://www.upenn.edu/">University of Pennsylvania</a>, US
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2012-leonardos">
							<i class="left-60 tog far fa-chevron-down"></i>
							Natural Image Segmentation by Medial Axis Decomposition
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2012.leonardos.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2012-leonardos">
							<div class="cv-detail just">
								<p>
									In the framework of this thesis, we present new image segmentation techniques based on a weighted medial axis decomposition procedure. Starting from image gradient or gray-scale contour map, we first compute a weighted distance map and its weighted medial axis by a linear-time process. Now, applying the same distance propagation from the medial axis backwards, we dually obtain an initial image partition and a graph representing image structure. This is equivalent to applying watershed transform on the weighted distance map, hence is both topological and contrast-weighted. However, it is more efficient because we first decompose the medial axis and then use our linear-time process to propagate on the remaining image surface. Using a disjoint-set data structure, we then merge adjacent regions according to different criteria.
								</p>
								<p>
									Several criteria were examined and tested. First, we use medial axis saddle point height to express similarity between adjacent regions and merge correspondingly. A second distinct direction we follow is to merge adjacent regions according to how fragmented they are. Last but not least, we use ultrametric contour map representation to implement hierarchical segmentation. As inter-region ultrametric dissimilarities, we use mean boundary strength on the common boundary between adjacent regions and inter-region fragmentation. All the above mentioned techniques are evaluated using the Berkeley Segmentation Dataset and compared with some state of the art algorithms. Without learning, we achieve performance near the state of the art with very practical running times. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2012-moustafelos"></a>
						<div class="cv-year">
							2011-2012
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="https://www.linkedin.com/in/charalampos-babis-moustafelos-2a216246/">Charalampos Moustafelos</a>
							<div class="cv-ref">
								now Consultant at
								<a href="https://www.d-fine.com/">d-fine</a>, Switzerland
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2012-moustafelos">
							<i class="left-60 tog far fa-chevron-down"></i>
							Image Search Using Visual Synonyms
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2012.moustafelos.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2012-moustafelos">
							<div class="cv-detail just">
								<p>
									In this diploma thesis we investigate large scale image retrieval. We describe the stages of image retrieval, giving emphasis in the visual vocabulary construction. Moreover, we mention the problems that arise due to quantization of the descriptors and introduce several techniques that appease them. More specifically, one of these techniques introduces the use of synonym visual words. In order to discover the synonym visual word we should construct sets of matching image patches, called feature tracks. For this purpose, we develop a novel technique for constructing feature tracks. Given a collection of geo-tagged images, we cluster these images according to (a) their locations and (b) their visual features. Hence we obtain view clusters: clusters with images that depict the same scene. Matching features are discovered, through geometric verification between the images in the cluster and the image reference (center of the cluster). Given the feature tracks, we can find matching visual words. Finally, we test and evaluate the performance of this technique implementing retrieval experiments in Oxford building dataset. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2009-koumoulos"></a>
						<div class="cv-year">
							2008-2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							George Koumoulos
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2009-koumoulos">
							<i class="left-60 tog far fa-chevron-down"></i>
							Image Analysis and Retrieval by Local Feature Detection
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2009.koumoulos.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2009-koumoulos">
							<div class="cv-detail just">
								<p>
									The large amount of optical information and the easy access to available data through the Internet has led to the emerging need for efficient description of image content. Many techniques for fast image retrieval have been proposed in literature, but in the recent years the use local features has come to maturity because of their efficiency.
								</p>
								<p>
									In this thesis, the most known methods of local detectors and descriptors are firstly studied. Next, an integrated system of local invariant features is implemented, with the use of already tested techniques, and different methods are combined in order to compose a powerful tool for image analysis. The experimental evaluation follows, which is done over a standard set (benchmark) of images under various transformations (photometric and geometric). All previously analyzed methods are compared via objective criteria: repeatability score, accuracy of detectors (localization), matching score and performance of descriptors.
								</p>
								<p>
									The efficiency of local features is testified in the image retrieval system with the use of large image databases. The experimental procedure provides a quantitative comparison of the aforementioned techniques. The main image retrieval mechanism is related to text retrieval methods: a visual vocabulary is created and a model vector is constructed for each image, which represents its semantic content. The image retrieval procedure is done through vector similarity measures. Different visual vocabularies (generated by various local feature methods) are compared with respect to image retrieval evaluation criteria, like precision, recall and mean Average Precision (mAP). 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2008-kalantidis"></a>
						<div class="cv-year">
							2007-2008
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://www.skamalas.com/">Yannis Kalantidis</a>
							<div class="cv-ref">
								now Research Scientist at
								<a href="https://europe.naverlabs.com/">Naver Labs Europe</a>, France
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2008-kalantidis">
							<i class="left-60 tog far fa-chevron-down"></i>
							Image Search Using Visual Features and Geometry
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2008.kalantidis.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2008-kalantidis">
							<div class="cv-detail just">
								<p>
									Over the recent years, the amount of digital images available online has increased rapidly. These huge multimedia collections contain diverse data and cover almost every aspect of life in terms of visual and semantic content. Proper indexing and analysis of such data is an essential process, in order to be able to retrieve its useful visual information. Searching through image libraries has become an everyday process, the same way as Google text-based search. In this diploma thesis, techniques for content-based image retrieval are presented and evaluated, and a web-based image search platform is created. Various techniques are applied, using either global or local features, such as the MPEG-7 and SURF descriptors, extracted locally, from points of interest or segmented regions. A bag-of-words model is used for indexing and geometric constraints are also taken into account. These techniques are evaluated over many common datasets, in order to test the universality of their use, towards a web-scale image retrieval system. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2008-varytimidis"></a>
						<div class="cv-year">
							2007-2008
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://image.ntua.gr/iva/chrisvar/">Christos Varytimidis</a>
							<div class="cv-ref">
								now Senior Machine Learning Engineer at
								<a href="https://www.workable.com/">Workable</a>, Greece
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2008-varytimidis">
							<i class="left-60 tog far fa-chevron-down"></i>
							Object Detection and Interactive Image Annotation
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2008.varytimidis.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2008-varytimidis">
							<div class="cv-detail just">
								<p>
									Object detection in images is a filed of image analysis that is searched intensively during the past few years. In this diploma thesis we present a complete object detection method which was created by Viola and Jones in 2001. Haar-like features are used to describe images, while the classification of the candidate regions of an image is performed by a cascade of classifiers created by the AdaBoost algorithm in order to increase detection speed. By using this method, we trained several detectors for interior parts of a car, as well as its exterior, with sample images from the LabelMe dataset. We show and explain the choices that were made in every detector training. The results of the evaluation of every detector are presented in precision-recall and receiver operator characteristic (ROC) diagrams. We also present some conclusions in order to achieve the best results from this method. In this diploma thesis we created a program for semi-automatic annotation of images, which detects objects in images using the presented method. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2007-tolias"></a>
						<div class="cv-year">
							2006-2007
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a href="http://cmp.felk.cvut.cz/~toliageo/">Giorgos Tolias</a>
							<div class="cv-ref">
								now Assistant Professor at
								<a href="http://cmp.felk.cvut.cz/">Center for Machine Perception</a>, Czech Republic
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2007-tolias">
							<i class="left-60 tog far fa-chevron-down"></i>
							Object Detection and Scene Classification Using MPEG-7 Descriptors and Visual Thesaurus
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2007.tolias.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2007-tolias">
							<div class="cv-detail just">
								<p>
									The enlarging audiovisual multimedia content during the last few years has emerged the need of automatic feature extraction and description of this content. With the use of various descriptors, including those defined by the MPEG-7 standard, its low level information is captured. In this diploma thesis MPEG-7 visual descriptors are examined and a descriptor extraction application is developed based on the MPEG-7 eXperimentation Model. This application is evaluated in order to verify its alignment to the XM. This application is then used within a high-level detection approach. A region-based technique is applied and a visual thesaurus is constructed to formalize knowledge. Neural-network detectors are trained in order to detect high-level concepts. Moreover, the utility of the well known Latent Semantic Analysis technique is investigated. The dataset of the TRECVID benchmark has been used for testing this techniques. Finally a car exterior/interior classification problem is also tackled. Extensive experimental results are presented for each of the aforementioned problems. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2007-makrimallis"></a>
						<div class="cv-year">
							2006-2007
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Antonis Makrimallis
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2007-makrimallis">
							<i class="left-60 tog far fa-chevron-down"></i>
							Person Detection Using Histograms of Oriented Gradients
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2007.makrimallis.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2007-makrimallis">
							<div class="cv-detail just">
								<p>
									Object detection in images or sequences of images is an important field of research in the past few years. This report studies a method for the detection of people in still images, with unconstrained scene conditions, such as complex background and uncontrolled lighting. A feature vector is used, which is adopts Histograms of Oriented Gradients (HOGs) in a dense grid on the image. The classification is achieved via a linear SVM. The study and evaluation of the method are being achieved through two implementations, which are differentiated by the choice of HOG features. Moreover, the sensitivity of each implementation in basic parameters of the method is evaluated, altering the values of these parameters. From the evaluations and observations, is concluded that the use of HOGs captures ideally the characteristics of human form and gives us reliable results for the detection of people in still images. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2006-giannekou"></a>
						<div class="cv-year">
							2005-2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							Vicky Giannekou
							<div class="cv-ref">
								now Software Engineer at
								<a href="https://www.intralot.com/">Intralot</a>, Greece
							</div>
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2006-giannekou">
							<i class="left-60 tog far fa-chevron-down"></i>
							Image Matching by Shape Analysis
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2006.giannekou.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2006-giannekou">
							<div class="cv-detail just">
								<p>
									Recent years have seen a rapid increase of the size of digital image collections. Recent research has focused on the efficient processing, searching and retrieval of similar images from a database. In this diploma thesis we study the representation and retrieval of similar images based on the curvature scale space (CSS) method in the presence of affine transformations. More specifically, we examine the robustness of the method under affine transformations and compare its performance with the performance of other alternative methods. In order to achieve invariance, we used curve normalization based on affine length parametrization and evaluated the effectiveness of this application.
								</p>
								<p>
									At experimental level, a database of curves (contours) of different categories of shapes has been constructed. Initially, by applying random affine transforms, we created a number of affine-transformed versions of the above curves. We then used the CSS method to represent and retrieve similar curves of shapes from the database. The resulting matching cost is a measure of comparison of curve similarity and indicates the effectiveness of the method. Finally, we study the application of an alternative normalization method instead of the affine length based normalization, which appears to improve the effectiveness of the CSS method. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="msc-2005-koumoulos"></a>
						<div class="cv-year">
							2004-2005
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							George Koumoulos
						</div>
						<a class="rel toggle collapsed mr" data-toggle="collapse" href="#col-msc-2005-koumoulos">
							<i class="left-60 tog far fa-chevron-down"></i>
							Image Sequence Summarization--Shot Detection and Key Frame Selection
						</a>
						<a class="lnk" href="../data/cv/pdf/msc/2005.koumoulos.pdf"><i class="faa fa-file-pdf2 pdf-icon"></i></a>
						<div class="collapse" id="col-msc-2005-koumoulos">
							<div class="cv-detail just">
								<p>
									Recently, the enlarging available video data has led to the emerging need for automatic analysis, synopsis and extraction of information from videos. Every video sequence consists of a number of shots, each of them containing temporally associated frames, while contiguous shots are connected to each other with some type of transition at their boundaries. The first step for any kind of video analysis seems to be the detection of these boundaries followed by a temporal segmentation of video, while the next and more important step is related with the synopsis or the summarization of video. This is achieved by selecting certain number of characteristic frames (key-frames) from each shot, so that the content of the shot is represented in a short and also meaningful way.
								</p>
								<p>
									In this diploma thesis, a video summarization system is being constructed, encapsulating shot change detection, feature extraction and key-frame selection. This system combines methods working directly on MPEG compressed domain and automatically locates shot changes of video. Features from each frame of the sequence are then extracted and their values produce a point in the feature space. Therefore the entire video sequence is represented by a trajectory in this multidimensional space. According to mathematical methods defining the curvature of a curve, the characteristic points of the curve are determined, in areas where locally extreme behavior is observed. The system automatically extracts the key-frames via points of local maxima and minima of curvature, irrespective of the video content.
								</p>
								<p>
									In this work, two different ways of computing curvature are compared, as well as and two other existing methods that use characteristic points of a curve. Experiments concern in the effectiveness of these methods in terms of video key-frame selection. We attempt to improve performance of these methods by applying the computational model of Visual Attention, in order to extract features from the salient regions of the image. Finally, through the results of these experiments we aim to indicate capabilities, disadvantages and cases of improving and expanding this video summarization system. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="eu"></a>
					<span class="mr">Research grants [European]</span>
					<i class="fal fa-coins"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2019-grapes"></a>
						<div class="cv-year">
							2019-2024
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Advisor</span>
							<a class="but acro" href="http://grapes-network.eu/">GRAPES</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2019-grapes">
							<i class="left-60 tog far fa-chevron-down"></i>
							learninG, pRocessing And oPtimizing shapES
						</a>
						<div class="cv-ref">
							H2020-860843 / MSCA-ITN
						</div>
						<div class="collapse" id="col-eu-2019-grapes">
							<div class="cv-detail just">
								<p>
									GRAPES aims at considerably advancing the state of the art in Mathematics, Computer-Aided Design, and Machine Learning in order to promote game changing approaches for generating, optimizing, and learning 3D shapes, along with a multisectoral training for young researchers. Recent advances in the above domains have solved numerous tasks concerning multimedia and 2D data. However, automation of 3D geometry processing and analysis lags severely behind, despite their importance in science, technology and everyday life, and the well-understood underlying mathematical principles. The CAD industry, although well established for more than 20 years, urgently requires advanced methods and tools for addressing new challenges.
								</p>
								<p>
									The scientific goal of GRAPES is to bridge this gap based on a multidisciplinary consortium composed of leaders in their respective fields. Top-notch research is also instrumental in forming the new generation of European scientists and engineers. Their disciplines span the spectrum from Computational Mathematics, Numerical Analysis, and Algorithm Design, up to Geometric Modeling, Shape Optimization, and Deep Learning. This allows the 15 PhD candidates to follow either a theoretical or an applied track and to gain knowledge from both research and innovation through a nexus of inter-sectoral secondments and Network-wide workshops.
								</p>
								<p>
									Horizontally, our results lead to open-source, prototype implementations, software integrated into commercial libraries as well as open benchmark datasets. These are indispensable for dissemination and training but also to promote innovation and technology transfer. Innovation relies on the active participation of SMEs, either as a beneficiary hosting an ESR or as associate partners hosting secondments. Concrete applications include simulation and fabrication, hydrodynamics and marine design, manufacturing and 3D printing, retrieval and mining, reconstruction and visualization, urban planning and autonomous driving. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2008-weknowit"></a>
						<div class="cv-year">
							2008-2011
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator and Coordinator</span>
							<a class="but acro" href="https://web.archive.org/web/2011/http://www.weknowit.eu/">WeKnowIt</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2008-weknowit">
							<i class="left-60 tog far fa-chevron-down"></i>
							Emerging, Collective Intelligence for Personal, Organisational and Social Use
						</a>
						<div class="cv-ref">
							FP7-215453 / IP
						</div>
						<div class="collapse" id="col-eu-2008-weknowit">
							<div class="cv-detail just">
								<p>
									The main objective of WeKnowIt is to develop novel techniques for exploiting multiple layers of intelligence from user-contributed content, which together constitute Collective Intelligence, a form of intelligence that emerges from the collaboration and competition among many individuals, and that seemingly has a mind of its own. To this end, input from various sources is analyzed and combined: from digital content items and contextual information (Media Intelligence), massive user feedback (Mass Intelligence), and users social interaction (Social Intelligence) so as to benefit end-users (Personal Intelligence) and organizations (Organizational Intelligence).
								</p>
								<p>
									The automatic generation of Collective Intelligence constitutes a departure from traditional methods for information sharing, since for example, semantic analysis has to fuse information from both the content itself and the social context, while at the same time the social dynamics have to be taken into account. Such intelligence provides added-value to the available content and renders existing procedures and workflows more efficient. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2008-jumas"></a>
						<div class="cv-year">
							2008-2010
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<a class="but acro" href="https://web.archive.org/web/2010/http://www.jumasproject.eu/">JUMAS</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2008-jumas">
							<i class="left-60 tog far fa-chevron-down"></i>
							Judicial Management by Digital Libraries Semantics
						</a>
						<div class="cv-ref">
							FP7-214306 / IP
						</div>
						<div class="collapse" id="col-eu-2008-jumas">
							<div class="cv-detail just">
								<p>
									Public administrations represent the largest information bound professional communities: among them the judicial sector is one of the largest, where the needs of cooperation are critical, creating an exceedingly large improvement potential through adoption of novel content management techniques and development of new solutions for its specific needs of retrieval and semantic analysis. This potential is even larger considering the growing transnational cooperation also among several national law systems, highlighting the need to adapt the technological profiles of new member states.
								</p>
								<p>
									In this context, JUMAS envisages an advanced knowledge management system able to extract semantics from multimedia data. JUMAS is tailored at managing situations where multiple cameras and audio sources are used to record assemblies and reconstructing debate sequences for future consultation. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2006-imagination"></a>
						<div class="cv-year">
							2006-2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<a class="but acro" href="https://web.archive.org/web/2009/http://www.imagination-project.org/">Imagination</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2006-imagination">
							<i class="left-60 tog far fa-chevron-down"></i>
							Image-Based Navigation in Multimedia Archives
						</a>
						<div class="cv-ref">
							FP6-034626 / STREP
						</div>
						<div class="collapse" id="col-eu-2006-imagination">
							<div class="cv-detail just">
								<p>
									The main objective of IMAGINATION is to bring digital cultural and scientific resources closer to their users, by making user interaction image-based and context-aware. Our ultimate aim is to enable users to navigate through digital cultural and scientific resources through its images. IMAGINATION will provide a novel image-based access method to digital cultural and scientific resources. It will reduce complexity by the provision of intuitive navigation method.
								</p>
								<p>
									IMAGINATION will facilitate an interactive and creative experience providing an intuitive navigation through images and parts of images. To do so IMAGINATION will combine, apply and improve existing techniques to provide a new way of navigation through cultural heritage multimedia archives. It will exploit the context of resources stored in its knowledge space by combining text-mining, image segmentation and image recognition algorithms. This combination will cause a synergy effect and will result in semi-automatically generated, high-level semantic metadata.
								</p>
								<p>
									The focus of IMAGINATION is on indexing, retrieving and exploring non-textual complex objects and will apply knowledge technologies and visualization techniques for improved navigation and access to multimedia collections. Comprehensive tool support (including an ontology editor and a semi-automated image annotation tool) will be provided, together with an easy-to-use web-based interface which visualizes the contextualized content stored in the IMAGINATION knowledge space.
								</p>
								<p>
									A major outcome of the project will be the new and intuitive approach of navigation trough images and a set of technologies and tools to support the annotation of images by manual, semi-automatic and automatic techniques. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2006-boemie"></a>
						<div class="cv-year">
							2006-2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<a class="but acro" href="https://web.archive.org/web/2009/http://www.boemie.org/">BOEMIE</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2006-boemie">
							<i class="left-60 tog far fa-chevron-down"></i>
							Bootstrapping Ontology Evolution with Multimedia Information Extraction
						</a>
						<div class="cv-ref">
							FP6-027538 / STREP
						</div>
						<div class="collapse" id="col-eu-2006-boemie">
							<div class="cv-detail just">
								<p>
									BOEMIE will pave the way towards automation of the process of knowledge acquisition from multimedia content, by introducing the notion of evolving multimedia ontologies, which will be used for the extraction of information from multimedia content in networked sources, both public and proprietary. BOEMIE advocates a synergistic approach that combines multimedia extraction and ontology evolution in a bootstrapping process involving, on the one hand, the continuous extraction of semantic information from multimedia content in order to populate and enrich the ontologies and, on the other hand, the deployment of these ontologies to enhance the robustness of the extraction system. The ambitious scope of the BOEMIE project and the proven specialized competence of the carefully composed project consortium ensure that the project will achieve the significant advancement of the state of the art needed to successfully merge the component technologies. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2006-mesh"></a>
						<div class="cv-year">
							2006-2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<a class="but acro" href="https://web.archive.org/web/2009/http://www.mesh-ip.eu/">MESH</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2006-mesh">
							<i class="left-60 tog far fa-chevron-down"></i>
							Multimedia Semantic Syndication for Enhanced News Services
						</a>
						<div class="cv-ref">
							FP6-027685 / IP
						</div>
						<div class="collapse" id="col-eu-2006-mesh">
							<div class="cv-detail just">
								<p>
									Multimedia Semantic Syndication for Enhanced News Services (MESH) will apply multimedia analysis and reasoning tools, network agents and content management techniques to extract, compare and combine meaning from multiple multimedia sources, and produce advanced personalized multimedia summaries, deeply linked among them and to the original sources to provide end users with an easy-to-use "multimedia mesh" concept, with enhanced navigation aids. A step further will empower users with the means to reuse available content by offering media enrichment and semantic mixing of both personal and network content, as well as automatic creation from semantic descriptions.
								</p>
								<p>
									Encompassing all the system, dynamic usage management will be included to facilitate agreement between content chain players (content providers, service providers and users). In a sentence, the project will create multimedia content brokers acting on behalf of users to acquire, process, create and present multimedia information personalized (to user) and adapted (to usage environment). These functions will be fully exhibited in the application area of news, by creation of a platform that will unify news organizations through the online retrieval, editing, authoring and publishing of news items. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2006-x-media"></a>
						<div class="cv-year">
							2006-2010
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<a class="but acro" href="https://web.archive.org/web/2010/http://nlp.shef.ac.uk/X-Media">X-Media</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2006-x-media">
							<i class="left-60 tog far fa-chevron-down"></i>
							Knowledge Sharing and Reuse Across Media
						</a>
						<div class="cv-ref">
							FP6-26978 / IP
						</div>
						<div class="collapse" id="col-eu-2006-x-media">
							<div class="cv-detail just">
								<p>
									X-Media addresses the issue of knowledge management in complex distributed environments. It will study,develop and implement large scale methodologies and techniques for knowledge management able to support sharing and reuse of knowledge that is distributed in different media (images, documents and data) and repositories (data bases, knowledge bases, document repositories, etc.) or that is inaccessible for current systems, which cannot capture the knowledge implicit across media. All the developed methodologies aim at seamlessly integrating with current work practices. Usability will be a major concern together with ease of customization for new applications.
								</p>
								<p>
									Technologies will be able to support knowledge workers in an effective way, (i) hiding the complexity of the underlying search/retrieval process, (ii) resulting in a natural access to knowledge, (iii) allowing interoperability between heterogeneous information resources and (iv) including heterogeneity of data type (data, image, texts). The expected impact on organizations is to dramatically improve access to, sharing of and use of information by humans as well as by and between machines. Expected benefits are a dramatic reduction of management costs and increasing feasibility of complex knowledge management tasks. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2006-k-space"></a>
						<div class="cv-year">
							2006-2008
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<a class="but acro" href="https://web.archive.org/web/2008/http://kspace.qmul.net/">K-Space</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2006-k-space">
							<i class="left-60 tog far fa-chevron-down"></i>
							Knowledge Space of Semantic Inference for Automatic Annotation and Retrieval of Multimedia Content
						</a>
						<div class="cv-ref">
							FP6-027026 / NoE
						</div>
						<div class="collapse" id="col-eu-2006-k-space">
							<div class="cv-detail just">
								<p>
									K-Space is a network of leading research teams from academia and industry conducting integrative research and dissemination activities in semantic inference for automatic and semi-automatic annotation and retrieval of multimedia content. K-Space exploits the complementary expertise of project partners, enables resource optimization and fosters innovative research in the field. The aim of K-Space research is to narrow the gap between low-level content descriptions that can be computed automatically by a machine and the richness and subjectivity of semantics in high-level human interpretations of audiovisual media: The Semantic Gap. Specifically, K-Space integrative research focus on three areas:
								</p>
								<p>
									(1) Content-based multimedia analysis: Tools and methodologies for low-level signal processing, object segmentation, audio/speech processing and text analysis, and audiovisual content structuring and description.
								</p>
								<p>
									(2) Knowledge extraction: Building of a multimedia ontology infrastructure, knowledge acquisition from multimedia content, knowledge-assisted multimedia analysis, context based multimedia mining and intelligent exploitation of user relevance feedback.
								</p>
								<p>
									(3) Semantic multimedia: Knowledge representation for multimedia, distributed semantic management of multimedia data, semantics-based interaction with multimedia and multimodal media analysis.
								</p>
								<p>
									An objective of the Network is to implement an open and expandable framework for collaborative research based on a common reference system. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2004-muscle"></a>
						<div class="cv-year">
							2004-2007
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<a class="but acro" href="https://web.archive.org/web/2007/http://www.muscle-noe.org/">MUSCLE</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2004-muscle">
							<i class="left-60 tog far fa-chevron-down"></i>
							Multimedia Understanding through Semantics, Computation and Learning
						</a>
						<div class="cv-ref">
							FP6-507752 / NoE
						</div>
						<div class="collapse" id="col-eu-2004-muscle">
							<div class="cv-detail just">
								<p>
									Due to the convergence of several strands of scientific and technological progress we are witnessing the emergence of unprecedented opportunities for the creation of a knowledge driven society. Indeed, databases are accruing large amounts of complex multimedia documents, networks allow fast and almost ubiquitous access to an abundance of resources and processors have the computational power to perform sophisticated and demanding algorithms. However, progress is hampered by the sheer amount and diversity of the available data. As a consequence, access can only be efficient if based directly on content and semantics, the extraction and indexing of which is only feasible if achieved automatically.
								</p>
								<p>
									Given the above, we feel that there is both a need and an opportunity to systematically incorporate machine learning into an integrated approach to multimedia data mining. Indeed, enriching multimedia databases with additional layers of automatically generated semantic metadata as well as with artificial intelligence to reason about these (meta)data, is the only conceivable way that we will be able to mine for complex content, and it is at this level that MUSCLE will focus its main effort. Realizing this vision will require breakthrough progress to alleviate a number of key bottlenecks along the path from data to understanding. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2004-acemedia"></a>
						<div class="cv-year">
							2004-2007
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<a class="but acro" href="https://web.archive.org/web/2007/http://www.acemedia.org/">aceMedia</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2004-acemedia">
							<i class="left-60 tog far fa-chevron-down"></i>
							Integrating Knowledge, Semantics and Content for User-Centred Intelligent Media Services
						</a>
						<div class="cv-ref">
							FP6-001765 / IP
						</div>
						<div class="collapse" id="col-eu-2004-acemedia">
							<div class="cv-detail just">
								<p>
									Long term market viability of multimedia services requires significant improvements to the tools, functionality, and systems to support target users. aceMedia seeks to overcome the barriers to market success which include user difficulties in finding desired content, limitations in the tools available to manage personal and purchased content, and high costs to commercial content owners for multimedia content processing and distribution, by creation of means to generate semantic-based, context and user aware content, able to adapt itself to user preferences and environments.
								</p>
								<p>
									aceMedia will build a system to extract and exploit meaning inherent to the content in order to automate annotation and to add functionality that makes it easier for all users to create, communicate, find, consume and re-use content. aceMedia targets knowledge discovery and embedded self-adaptability to enable content to be self organizing, self annotating, self associating; more readily searched (faster, more relevant results); and adaptable to user requirements (self reformatting).
								</p>
								<p>
									aceMedia introduces the novel concept of the Autonomous Content Entity (ACE), which has three layers: content, its associated metadata, and an intelligence layer consisting of distributed functions that enable the content to instantiate itself according to its context (e.g. network, user terminal, user preferences). The ACE may be created by a commercial content provider, to enable personalized self-announcement and automatic content collections, or may be created in a personal content system in order to make summaries of personal content, or automatically create personal albums of linked content.
								</p>
								<p>
									The ACE concept will be verified by two user focused application prototypes, enabled for both home network and mobile communication environments. This enables the aceMedia partners to evaluate the technical feasibility and user acceptance of the ACE concept, with a view to market exploitation after the end of the project. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2002-mirror"></a>
						<div class="cv-year">
							2002-2004
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator and Coordinator</span>
							<a class="but acro" href="https://web.archive.org/web/2004/http://www.mirror-project.net/">MIRROR</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2002-mirror">
							<i class="left-60 tog far fa-chevron-down"></i>
							World Communities of Practice for Learning and Innovation in Natural Science
						</a>
						<div class="cv-ref">
							IST-2001-32504
						</div>
						<div class="collapse" id="col-eu-2002-mirror">
							<div class="cv-detail just">
								<p>
									MIRROR aims to create a collection of components and tools for a distributed knowledge management system that will support physical and social interactions. Mirror aims to establish a Europe-wide community of practice for learning and innovation in the area of natural sciences museums by developing a novel learning methodology and by implementing state-of-the-art tools, techniques and systems. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-2001-faethon"></a>
						<div class="cv-year">
							2001-2003
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator and Technical Leader</span>
							<a class="but acro" href="https://web.archive.org/web/2003/http://image.ntua.gr/faethon">FAETHON</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-2001-faethon">
							<i class="left-60 tog far fa-chevron-down"></i>
							Unified Intelligent Access to Heterogeneous Audiovisual Content
						</a>
						<div class="cv-ref">
							IST-1999-20502
						</div>
						<div class="collapse" id="col-eu-2001-faethon">
							<div class="cv-detail just">
								<p>
									The overall objective of FAETHON project is to develop an integrated information system that offers enhanced search and retrieval capabilities to users of digital audiovisual (a/v) archives. This novel system will exploit the advances in handling a/v content and related metadata, as introduced by MPEG-4 and worked out by MPEG-7, to offer advanced access services characterized by the tri-fold "semantic phrasing of the request (query)", "unified handling" and "personalized response".
								</p>
								<p>
									From a technical point of view, the proposed system will play the role of an intermediate access server residing between the end users and multiple heterogeneous audiovisual archives organized according to new MPEG standards. Various types of interfacing modules will be designed/ implemented to support smooth communication of the intermediate server to the a/v archives. The major final product will be an integrated software system consisting of the two, semantic unification and personalization subsystems, together with two types of interfaces. Namely, those between the system and the individual a/v archives and those between the system and the end-users. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-1997-physta"></a>
						<div class="cv-year">
							1997-2001
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<a class="but acro" href="https://web.archive.org/web/2001/http://image.ntua.gr/physta">PHYSTA</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-1997-physta">
							<i class="left-60 tog far fa-chevron-down"></i>
							Principled Hybrid Systems Theory and Applications
						</a>
						<div class="cv-ref">
							Training and Mobility of Research
						</div>
						<div class="collapse" id="col-eu-1997-physta">
							<div class="cv-detail just">
								<p>
									Systematic principles for integrating symbolic and subsymbolic processing will be developed in the project. Key aims are to ensure that the resulting total hybrid system retains desirable properties of both processing levels. On the one side the signal processing abilities, robustness and learning capability of neural networks should be preserved. On the other side advantage should be taken of the ability of rule-based systems to exploit high level knowledge and existing algorithms and to explain (to a user) why conclusions were reached in particular cases. The methodologies to be developed in the project will be tested in a challenging application related to human computer interaction, which is recognition of emotion based on both voice and visual cues. Low level features will be extracted from signals using neural networks and subsequent formulation of rules will provide a conceptual framework, substantial for emotion analysis. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-1998-modulates"></a>
						<div class="cv-year">
							1998-1999
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<span class="acro but">MODULATES</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-1998-modulates">
							<i class="left-60 tog far fa-chevron-down"></i>
							Multimedia Organization for Developing the Understanding and Learning of Advanced Technology in European Schools
						</a>
						<div class="cv-ref">
							Educational Multimedia Task Force
						</div>
						<div class="collapse" id="col-eu-1998-modulates">
							<div class="cv-detail just">
								<p>
									This EU-funded project aims to establish a pilot European multimedia network and organization with the purpose of motivating encouraging school pupils to take up a career in technology and related businesses and industries, and to assist with the learning of languages within the context of learning about technological subjects in school at both primary and secondary level. The network will take the structural form of a group of European universities with skills in the development and use of multimedia materials and experience in teacher training working together with teachers and pupils in schools to provide a unified range of user configurable, multi-lingual, multimedia courses on topics in advanced technology for primary and secondary schools. Course materials will be developed in at least 6 topics with all materials available in English, German, and Greek.
								</p>
								<p>
									The project will be of 2 years duration starting in early 1998. ISDN links will be established between the 3 participating universities and from each of the universities to its group of schools (14 schools in total). Telecommunications service providers will establish these connections and be involved as partners in the project to assist with technical developments as well as with commercial aspects for exploitation of results. The project will form the pilot study for the creation of a self-funding European educational multimedia network and organization for the teaching and learning of advanced technology which has the capability of assisting language teaching. In the 2 years following the project (2000-2002) it is planned to provide access to MODULATES materials for over 1,000 schools throughout the EU. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-1996-mcube"></a>
						<div class="cv-year">
							1996-1999
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<a class="but acro" href="https://web.archive.org/web/1999/http://www.mcube.org/">MCUBE</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-1996-mcube">
							<i class="left-60 tog far fa-chevron-down"></i>
							Mediterranean Multimedia - Multimedia Support Center for Culture and Arts
						</a>
						<div class="cv-ref">
							ESPRIT 22266 Multimedia Support Centers
						</div>
						<div class="collapse" id="col-eu-1996-mcube">
							<div class="cv-detail just">
								<p>
									The M.CUBE is an Esprit project co-financed by European Commission. It promotes the production of European multimedia and supports producers, companies, publishers and other cultural and technological bodies interested in applying multimedia technology to the cultural field. The aim of the project is to create a multimedia support network, based on four Mediterranean regions, dedicated to fostering the development of European multimedia applications in the area of culture and arts.
								</p>
								<p>
									The main objectives of M.CUBE are to (i) improve the competitiveness of the European multimedia industry, enhancing the quality of its products, improving the business capabilities of the enterprises, and attracting funds for new developments, (ii) create a critical mass to penetrate the consumer market at international level, putting together many small developers to address the market through big distributors, and (iii) exploit the enormous European potential in terms of cultural contents. Supplying multimedia support services to cultural users is a strategic task for M.CUBE. Museums, galleries, collections, public administrations, etc. are pilot users and clients of advanced technological solutions, based on the application of multimedia to culture and arts.
								</p>
								<p>
									The M.CUBE contribution is to: First, contribute to the development of a whole editorial line, defining technical and artistic contents, market targets and channels, certification process, methodological recommendations, policy and programmes. Second, create a network of manufacturers, through setting up local associations and the development of international exchanges. Third, develop business opportunities with the final aim of stimulating new markets. Fourth, provide a large set of services through intermediation and direct delivery, technological and manufacturing services, training, access to multimedia repositories, certification, consulting activities, information desk, etc. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eu-1993-manadix"></a>
						<div class="cv-year">
							1993-1996
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<a class="but acro" href="https://web.archive.org/web/1996/http://gps-tsc.upc.es/imatge/_Philippe/MANADIX.html">MANADIX</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-eu-1993-manadix">
							<i class="left-60 tog far fa-chevron-down"></i>
							Motion Analysis in Advanced Image Communication Systems
						</a>
						<div class="cv-ref">
							Human Capital and Mobility
						</div>
						<div class="collapse" id="col-eu-1993-manadix">
							<div class="cv-detail just">
								<p>
									The project revolved around information extraction techniques from video sequences in order to detect and minimize data unnecessary to transmit. Our contribution was mainly in the fields of multiresolution techniques and hierarchical representation of images and in the use of ROIs (Regions of Interest) for efficient coding and compression of images. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="fr"></a>
					<span class="mr">Research grants [French]</span>
					<i class="fal fa-coins"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="fr-2020-mqa"></a>
						<div class="cv-year">
							2020-2023
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<span class="acro but">MQA</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-fr-2020-mqa">
							<i class="left-60 tog far fa-chevron-down"></i>
							Semantic Multimodal Question Answering in Domestic Environments
						</a>
						<div class="cv-ref">
							CIFRE-2020
						</div>
						<div class="collapse" id="col-fr-2020-mqa">
							<div class="cv-detail just">
								<p>
									Visual scene analysis and understanding research has gone from low level concepts (e.g. object detection and segmentation) to high level semantic understanding, such as visual interestingness, memorability and image/video captioning. At the same time, there is progress beyond unimodal processing towards solving multimodal problems. Visual question answering (VQA) and visual dialog have achieved a great attention as means of AI systems interacting with humans in conversational language about visual content.
								</p>
								<p>
									VQA is often treated as a classification problem: Using deep visual and language representations, a classifier predicts a probability distribution over a fixed list of frequent answers. Recent methods use attention models on both image and question. At the same time, memory networks are used for scene understanding and question answering over a long period of time.
								</p>
								<p>
									This is a CIFRE PhD thesis project with InterDigital, aiming at designing novel question answering techniques based on deep learning to improve living experience at home. In particular, it will investigate moving from image understanding towards long-term multimodal-based context understanding. This may allow answering questions based on what has happened in the past. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="fr-2020-meerqat"></a>
						<div class="cv-year">
							2020-2023
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<span class="acro but">MEERQAT</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-fr-2020-meerqat">
							<i class="left-60 tog far fa-chevron-down"></i>
							MultimEdia Entity Representation and Question Answering Tasks
						</a>
						<div class="cv-ref">
							ANR-19-CE23-0028
						</div>
						<div class="collapse" id="col-fr-2020-meerqat">
							<div class="cv-detail just">
								<p>
									We propose to address the problem of ambiguities of visual and textual content by learning and then combining their representations. As a use case, we propose to solve a new scientific task, namely Multimedia Question Answering, using three different sources of information. The task consists in answering a textual question associated with visual data, relying on an external knowledge base containing millions of unique entities. Each entity is represented by textual and visual content as well as links to other entities. In practice, we focus on four types of entities, namely persons, organisations (e.g. companies, NGOs, intergovernmental organizations), geographical points of interest (e.g. touristic places, remarkable buildings) and objects (e.g. commercial products). Achieving this objective requires to progress on the disambiguation of each modality with respect to the others and the knowdge base. We also propose to merge the representations into a common tri-modal space.
								</p>
								<p>
									An important problem will be to determine the content to associate to an entity to adequately represent it, depending on its type (person, object, organisation, place). Since an entity can be associated to several vectors, each originating in a different modality, the challenge is to define a representation that is compact (for performance) while still expressive enough to reflect the potential links of the entity to other entities. The project has a potential economic impact in the fields of data intelligence, including applications in marketing, security, tourism and cultural heritage. In case of success, the output of the MEERQAT project could directly contribute to improve chatbots. During the project, the direct output will be mainly academic, consisting of scientfic articles with the corresponding material to reproduce experiments. We also plan to release a new benchmark for the proposed task, in the context of an international evaluation campaign. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="fr-2020-unlir"></a>
						<div class="cv-year">
							2020-2024
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Scientific Partner</span>
							<span class="acro but">UNLIR</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-fr-2020-unlir">
							<i class="left-60 tog far fa-chevron-down"></i>
							Unsupervised Representation Learning for Image Recognition
						</a>
						<div class="cv-ref">
							ANR-2019-103385 / JCJC
						</div>
						<div class="collapse" id="col-fr-2020-unlir">
							<div class="cv-detail just">
								<p>
									The proposed project lies in the field of computer vision, pattern recognition, and machine learning. We particularly study two problems of image recognition, image classification and image retrieval. Like machine learning, computer vision has witnessed a core change with the recent repopularization of Deep Neural Networks (DNN). Despite the success of DNN, several limitations are to be investigated.
								</p>
								<p>
									(1) Complex recognition problems such as fine grained classification (highly similar categories e.g. bird species, airplane/car models, etc.) show that state of the art DNNs are still improved by better objective functions and more discriminative intermediate representations.
								</p>
								<p>
									(2) Despite progress in using less annotated data, DNN can hardly cope with learning from few examples.
								</p>
								<p>
									(3) DNNs have so many parameters and complex structures that it is extremely hard to understand what happens in every layer in producing the final decision.
								</p>
								<p>
									This project aims to address these limitations. In particular, we will work towards building networks capable of solving fine-grained visual recognition tasks. We will improve the capabilities of networks to learn from few to no data, building highly discriminative representations that can address complex recognition problems. Following that, we will provide insight on how such models take their decisions. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="fr-2018-bnf"></a>
						<div class="cv-year">
							2018-2019
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<span class="acro but">BnF</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-fr-2018-bnf">
							<i class="left-60 tog far fa-chevron-down"></i>
							Classification of cultural heritage images
						</a>
						<div class="cv-ref">
							MIC/BnF
						</div>
						<div class="collapse" id="col-fr-2018-bnf">
							<div class="cv-detail just">
								<p>
									For several years, Bibliothèque nationale de France (BnF) has been pursuing its policy of enriching its Gallica digital library with specialized collections, the main feature of which is to create batches of still images of printed or handwritten text. Thus, important batches of books, manuscripts, newspapers and magazines, photographs, maps, stamps, coins, sound recordings and scores have been added to Gallica. The impossibility of manually indexing all iconographic collections by unit encourages the adoption of an image indexing solution based on the automatic or semi-automatic analysis of their visual content. The objective is to specialize an image classification tool in heritage corpora in order to add semantics to the image analysis process. The challenge is to make the richness of these collections accessible to as many people as possible (general public and professionals), through intuitive and ergonomic tools and interfaces.
								</p>
								<p>
									In this context, the objective of the project is to investigate automatic classification of images in Gallica according to their visual content, and producing annotations that could enrich existing metadata. The experience of Linkmedia in visual indexing and deep learning makes it possible to consider an experiment on the particular contents of the BnF. The project consists of the following.
								</p>
								<p>
									(1) Identify an experimental iconographic corpus from Gallica digital collections.
								</p>
								<p>
									(2) Build a prototype visual classification engine on this corpus.
								</p>
								<p>
									(3) Evaluate the performance of the prototype by controlled evaluation using ground truth and by the Gallica Studio community. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="fr-2018-few-shot"></a>
						<div class="cv-year">
							2018-2021
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-fr-2018-few-shot">
							<i class="left-60 tog far fa-chevron-down"></i>
							Few-shot learning for object recognition in aerial images
						</a>
						<div class="cv-ref">
							CIFRE-2017-1744
						</div>
						<div class="collapse" id="col-fr-2018-few-shot">
							<div class="cv-detail just">
								<p>
									Learning from few training samples is a topic that enjoys a great scientific and industrial interest. In fact, deep learning approaches developed and advanced in recent years, have been typically relying on huge amounts of data. Most recently, given the impressive performances of deep models in various large-scale tasks, the scientific community has started exploring the feasibility of these powerful techniques for other tasks with reduced amounts of available data. There are plenty of cases where access to high volumes of data is potentially difficult or expensive or where the number of available training samples is intrinsically low. For such cases, the learning strategy of these multi-million parameters architectures needs to be rethought in order to allow the networks to squeeze out the maximum amount of information from the few available samples.
								</p>
								<p>
									This is a CIFRE PhD thesis project with Safran Tech, aiming to study architectures and learning methods most suitable for object recognition from few samples and to validate these approaches on multiple recognition tasks and use-cases in aerial imagery. In particular, use cases include (1) target objects being small in the image; (2) recognizing objects of the same class; (3) recognizing instances of the same object. The operational context of the recognition tasks requires the ability to recognize objects from a small image corpus with possibly large variations in illumination, orientation and context of the object of interest. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="fr-2018-mobilai"></a>
						<div class="cv-year">
							2018-2020
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<span class="acro but">MobilAI</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-fr-2018-mobilai">
							<i class="left-60 tog far fa-chevron-down"></i>
							Computer vision for smart phones
						</a>
						<div class="cv-ref">
							Images & Réseaux AAP-PME-2017
						</div>
						<div class="collapse" id="col-fr-2018-mobilai">
							<div class="cv-detail just">
								<p>
									The ability of our mobile devices to process visual information is currently not limited by their camera or computing power but by the network. Many mobile apps suffer from long latency due to data transmitted over the network for visual search. MobilAI aims to provide fast visual recognition on mobile devices, offering quality user experience whatever the network conditions. The idea is to transfer efficient deep learning solutions for image classification and retrieval onto embedded platforms such as smart phones. The intention is to use such solutions in B2B and B2C application contexts, for instance recognizing products and ordering online, accessing information about artifacts in exhibitions, or identifying identity documents. In all cases, visual recognition is performed on the device, with minimal or no access to the network. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="el"></a>
					<span class="mr">Research grants [Greek]</span>
					<i class="fal fa-coins"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="el-2011-is-helleana"></a>
						<div class="cv-year">
							2011-2014
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<a class="but acro" href="https://web.archive.org/web/2014/http://www.helleana.gr/">IS-Helleana</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-el-2011-is-helleana">
							<i class="left-60 tog far fa-chevron-down"></i>
							Intelligent System for HELLEnic Audiovisual National Aggregator
						</a>
						<div class="cv-ref">
							EPAN II 09SYN-72-922
						</div>
						<div class="collapse" id="col-el-2011-is-helleana">
							<div class="cv-detail just">
								<p>
									IS-Helleana aims to implement modern Semantic Web technologies for the development of an integrated system for unified access, management, search and interactive presentation of the Greek audiovisual inventory. The system will enable audiovisual content providers to display their content in a single interoperable way, within the context of a generalized semantic, rich display of the Greek audiovisual inventory, both in Greece and internationally, and users to effectively search for content and participate in the online interactive services provided by audiovisual content providers. The basic tool to achieve this goal is an online platform for semantic integration, management, enrichment and visualization of the audiovisual inventory. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="el-2006-eikonognosia"></a>
						<div class="cv-year">
							2006-2008
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<span class="acro but">Eikonognosia</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-el-2006-eikonognosia">
							<i class="left-60 tog far fa-chevron-down"></i>
							Management and Advanced Access to Scientific Data and Documentation of Byzantine Works of Art
						</a>
						<div class="cv-ref">
							Image, Sound and Language Processing
						</div>
						<div class="collapse" id="col-el-2006-eikonognosia">
							<div class="cv-detail just">
								<p>
									The documentation and analysis of Byzantine Art is an important component of the overall effort to maintain cultural heritage and contributes to learning and comprehending ones history traversal path. Efficient publishing of the multi-dimensional and multifaceted information that is necessary for the complete documentation of artworks should draw on a good organization of the data.
								</p>
								<p>
									Eikonognosia is a research project funded by the Greek General Secretariat of Research and Technology (GSRT) that aims to efficiently organize and publish detailed information about icons in the World Wide Web. Information derived from the analysis conducted in the Art Diagnosis Center of Ormylia Foundation is taken as a case study.
								</p>
								<p>
									Eikonognosia provides the means for organizing detailed and multidimensional information about Byzantine icons in a way that is compatible to international standards (CIDOC-CRM - ISO 21127:2006) and allows for an easy retrieval of data with advanced semantic web technologies. The ultimate goal for Eikonognosia is to foster the cultural heritage community by providing an integrated framework that helps to facilitate organization, retrieval and presentation of data from the cultural heritage domain. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="el-2006-ontomedia"></a>
						<div class="cv-year">
							2006-2008
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<a class="but acro" href="https://web.archive.org/web/2008/http://www.iti.gr/db.php/en/projects/ONTOMEDIA.html">OntoMedia</a>
						</div>
						Semantic Multimedia Content Analysis Using Knowledge Technologies
						<div class="cv-ref">
							PENED
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="el-2006-deltio"></a>
						<div class="cv-year">
							2006-2007
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<a class="but acro" href="https://web.archive.org/web/2007/http://www.atc.gr/deltio/">DELTIO</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-el-2006-deltio">
							<i class="left-60 tog far fa-chevron-down"></i>
							Multimedia Content Analysis using Ontology Evolution with Application to TV News Programs
						</a>
						<div class="cv-ref">
							Image, Sound and Language Processing
						</div>
						<div class="collapse" id="col-el-2006-deltio">
							<div class="cv-detail just">
								<p>
									The pbjective of the project is the development of innovative techniques for the representation, analysis and extraction of semantic information for the manipulation of multimedia content, with emphasis on their application to television news bulletins. Research and development will concentrate on techniques that enable the automatic analysis of multimedia content and the extraction of knowledge, resulting in the (semi-)automatic creation of metadata, as well as provide support for smart, semantic search services. The final output of the project will be a system for the analysis of television new bulletins, which will provide intelligent search functionalities in archives of digital television material. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="el-2004-visualasset"></a>
						<div class="cv-year">
							2004-2007
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<span class="acro but">VisualAsset</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-el-2004-visualasset">
							<i class="left-60 tog far fa-chevron-down"></i>
							Multimedia Document Analysis, Information Extraction and Management
						</a>
						<div class="cv-ref">
							EPAN-03DSBEPRO-44
						</div>
						<div class="collapse" id="col-el-2004-visualasset">
							<div class="cv-detail just">
								<p>
									The main scope of the proposed framework is the development of innovative analysis techniques, export of semantic information and management of multimedia content in general and multimedia documents in particular. The proposed system, called Visual Asset, will be constituted by a number of distinguishable subsystems that will undertake the different stages of processing, analysis, storage and access to content provided by multimedia documents (texts, images, video, audio and 3D representations) and are summarized in the following:
								</p>
								<p>
									(1) Image and video processing subsystem aiming at automatic export of low level characteristics (color, texture, form, movement, speed, etc) and export of characteristic parts of objects (object segmentation) (e.g. segmentation of persons in a video sequence). These results will be used in the system integrating visual and textual information via the use of ontologies, but also in the effective search and retrieval system, based on visual information.
								</p>
								<p>
									(2) Integration of visual and textual information subsystem. Object of this subsystem will be representation of knowledge with use of ontologies, analysis of multimedia content based on visual and textual and production of metadata with a common way of representation, regarding both textual and visual information.
								</p>
								<p>
									(3) Modeling and logical analysis of documents subsystem, aiming at automatic categorization and creation of effective search and retrieval applications, providing advanced functionalities in organization and management of big document volumes. The subsystem will integrate visual and textual information results and will use the notion of context in a document in order to fulfill the tasks of automatic categorization, logical analysis (table of contents, automatic recognition of chapters, titles, notes, reports in images, video, etc) and efficient search and retrieval. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="el-2003-multimine"></a>
						<div class="cv-year">
							2003-2005
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Principal Investigator</span>
							<a class="but acro" href="https://web.archive.org/web/2005/http://www.multimine.gr/">MultiMine</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-el-2003-multimine">
							<i class="left-60 tog far fa-chevron-down"></i>
							Research and Technology Training Network in Multimedia Knowledge Discovery and Management
						</a>
						<div class="cv-ref">
							EPAN
						</div>
						<div class="collapse" id="col-el-2003-multimine">
							<div class="cv-detail just">
								<p>
									The network, consisting of six Greek academic institutions and two SMEs, will organize a series of training activities in order to introduce knowledge technologies for multimedia content in Greek research and commercial institutions. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="el-1999-panorama"></a>
						<div class="cv-year">
							1999-2001
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<a class="but acro" href="https://web.archive.org/web/2001/http://uranus.ee.auth.gr/ipl/projects/epet99.html">PANORAMA</a>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-el-1999-panorama">
							<i class="left-60 tog far fa-chevron-down"></i>
							An Intelligent System for Retrieval and Mining of Audiovisual Material
						</a>
						<div class="cv-ref">
							EPET II - EKBAN
						</div>
						<div class="collapse" id="col-el-1999-panorama">
							<div class="cv-detail just">
								<p>
									PANORAMA aims at development of a system for efficient search and mining of audiovisual data from large distributed multimedia databases through several types of networks (Internet, intranets, etc.). The main objectives of the project are the interoperability of databases and the availability of software products and services on networks for open multimedia access. Digitalization of archives assets should provide all possible information (video, images, sound, texts, etc.) for wide public and professional use.
								</p>
								<p>
									Main subjects for implementation are the content-based retrieval from multimedia databases as well as search and extraction of characteristic scenes from video data for insertion in synthetic environments. Definition of audiovisual objects should be adopted within the framework of MPEG-4 and MPEG-7 standards in order to focus the project on the application of emerging technologies. Intellectual property rights and copyrights, preservation and security of the information are points that focusing specific attention by using innovative methods for protection such as watermarking for video data authentication and several encryption techniques. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="el-1997-vod"></a>
						<div class="cv-year">
							1997-2000
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<span class="acro but">VoD</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-el-1997-vod">
							<i class="left-60 tog far fa-chevron-down"></i>
							Video-on-Demand System Using the MPEG-2 Standard
						</a>
						<div class="cv-ref">
							SYN-96
						</div>
						<div class="collapse" id="col-el-1997-vod">
							<div class="cv-detail just">
								<p>
									The objective of the project is the design and prototype implementation of a Video on Demand (VoD) and Near Video on Demand (NVoD) system based on MPEG-2 digital video/audio technology. IVML and INFOLAB are exploiting their long experience in digital video applications and related services to bring to the market the final product - hardware and software - called "InTV". This product serves hotels and hospitals, providing them with the ability to offer VOD services to their clients on a pay-per-view basis.
								</p>
								<p>
									InTV uses state of the art technologies such as high quality MPEG-2 video and is built on mature and evolving platforms including the Oracle Video Server. Movies are stored in MPEG-2 format in the video server's hard disks, and video streams are transmitted to the subscribers' rooms using a local area network. End-users are able to watch movies on a terminal (monitor or TV set) connected to a set-top-box and send messages from the set-top box back to the video server, using an infrared remote control.
								</p>
								<p>
									The system provides both VoD and NVoD channels, including broadcast TV channels, and supports interactive movie selection as well as standard VCR controls (play/stop, pause, fast forward/rewind etc.) for the VoD service. The integrated InTV system offers a variety of features that make it attractive for mid and large sized hotel type enterprises, including scaleable architecture, easy installation and maintenance, interactive client service, pre-scheduled movies and flexible charging schemes. Optionally, it integrates other advanced features and on-line services, such as connection to Internet, web browsing, e-mail, etc. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="el-1997-ivml"></a>
						<div class="cv-year">
							1997-1999
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<span class="acro but">IVML</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-el-1997-ivml">
							<i class="left-60 tog far fa-chevron-down"></i>
							Image, Video and Multimedia Systems Laboratory
						</a>
						<div class="cv-ref">
							EPET II Service Providing Laboratories
						</div>
						<div class="collapse" id="col-el-1997-ivml">
							<div class="cv-detail just">
								<p>
									This projects aims at the improvement of the IVML with the acquisition of modern equipment in order to provide better cooperation with other Greek partners in matters of editing, analysis and synthesis of images and video sequences as well as transmission, storage and retrieval in multimedia environments. This includes certification along the ISO 9001 standard. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="el-1995-nika"></a>
						<div class="cv-year">
							1995-1997
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Researcher</span>
							<span class="acro but">NIKA</span>
						</div>
						<a class="rel toggle collapsed" data-toggle="collapse" href="#col-el-1995-nika">
							<i class="left-60 tog far fa-chevron-down"></i>
							Generalized Medical Image Processing and Management System
						</a>
						<div class="cv-ref">
							EKBAN-504
						</div>
						<div class="collapse" id="col-el-1995-nika">
							<div class="cv-detail just">
								<p>
									The aim of the project was the design and operation of an integrated PACS system for the best Greek Hospital for the treatment of Cardiomascular Diseases. The PACS has the ability to transmit and store radiology images, ultrasound still images, ultrasound video images of the heart, gamma-camera images and angiography video. 
								</p>
							</div>
						</div>
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="act"></a>
					<span class="mr">Conference organization</span>
					<i class="fal fa-chart-network"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2022-cvpr"></a>
						<div class="cv-year">
							2022
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Area Chair</span>
				
							<a class="but acro" href="http://cvpr2022.thecvf.com/">CVPR&nbsp;2022</a>
						</div>
						<a href="http://cvpr2022.thecvf.com/">IEEE/CVF Conference on Computer Vision and Pattern Recognition</a>
						<div class="cv-ref">
							New Orleans, Louisiana <span class="bull"></span> June 21-24, 2022
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2019-acm-mm"></a>
						<div class="cv-year">
							2019
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Workshops Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2019/http://www.acmmm.org/2019/">ACM-MM&nbsp;2019</a>
						</div>
						<a href="https://web.archive.org/web/2019/http://www.acmmm.org/2019/">27th ACM Multimedia Conference</a>
						<div class="cv-ref">
							Nice, France <span class="bull"></span> Oct 21-25, 2019
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2017-acm-mm"></a>
						<div class="cv-year">
							2017
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Area Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2017/http://www.acmmm.org/2017/">ACM-MM&nbsp;2017</a>
						</div>
						<em>Multimedia Search and Recommendation</em><br>
						<a href="https://web.archive.org/web/2017/http://www.acmmm.org/2017/">25th ACM Multimedia Conference</a>
						<div class="cv-ref">
							Mountain View, CA, USA <span class="bull"></span> Oct 23-27, 2017
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2017-eusipco"></a>
						<div class="cv-year">
							2017
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Area Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2017/https://www.eusipco2017.org/">EUSIPCO&nbsp;2017</a>
						</div>
						<em>Image, Video, and Multimedia Processing</em><br>
						<a href="https://web.archive.org/web/2017/https://www.eusipco2017.org/">25th European Signal Processing Conference</a>
						<div class="cv-ref">
							Kos, Greece <span class="bull"></span> Aug 28-Sep 2, 2017
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2009-civr"></a>
						<div class="cv-year">
							2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Program Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2009/http://www.civr2009.org/">CIVR&nbsp;2009</a>
						</div>
						<a href="https://web.archive.org/web/2009/http://www.civr2009.org/">ACM International Conference on Image and Video Retrieval</a>
						<div class="cv-ref">
							Santorini, Greece <span class="bull"></span> Jul 8-10, 2009
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2009-cbmi"></a>
						<div class="cv-year">
							2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">General Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2009/http://www.cbmi2009.org/">CBMI&nbsp;2009</a>
						</div>
						<a href="https://web.archive.org/web/2009/http://www.cbmi2009.org/">7th International Workshop on Content-Based Multimedia Indexing</a>
						<div class="cv-ref">
							Chania, Greece <span class="bull"></span> Jun 3-5, 2009
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2009-mmm"></a>
						<div class="cv-year">
							2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Program Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2009/http://mmm2009.eurecom.fr/">MMM&nbsp;2009</a>
						</div>
						<a href="https://web.archive.org/web/2009/http://mmm2009.eurecom.fr/">15th International Multimedia Modeling Conference</a>
						<div class="cv-ref">
							Sophia-Antipolis, France <span class="bull"></span> Jan 7-9, 2009
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2007-samt"></a>
						<div class="cv-year">
							2007
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">General Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2007/http://samt2007.ge.imati.cnr.it/">SAMT&nbsp;2007</a>
						</div>
						<a href="https://web.archive.org/web/2007/http://samt2007.ge.imati.cnr.it/">Second International Conference on Semantic and Digital Media Technologies</a>
						<div class="cv-ref">
							Genova, Italy <span class="bull"></span> Dec 5-7, 2007
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2007-wiamis"></a>
						<div class="cv-year">
							2007
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">General Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2007/http://mkg.iti.gr/wiamis2007">WIAMIS&nbsp;2007</a>
						</div>
						<a href="https://web.archive.org/web/2007/http://mkg.iti.gr/wiamis2007">8th International Workshop on Image Analysis for Multimedia Interactive Services</a>
						<div class="cv-ref">
							Santorini, Greece <span class="bull"></span> Jun 6-8, 2007
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2006-samt"></a>
						<div class="cv-year">
							2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">General Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2006/http://samt2006.org/">SAMT&nbsp;2006</a>
						</div>
						<a href="https://web.archive.org/web/2006/http://samt2006.org/">1st International Conference on Semantic and Digital Media Technologies</a>
						<div class="cv-ref">
							Athens, Greece <span class="bull"></span> Dec 6-8, 2006
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2006-kmc/ist"></a>
						<div class="cv-year">
							2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Organizer</span>
				
							<a class="but acro" href="https://web.archive.org/web/2006/http://mkg.iti.gr/ist2006/index.html">KMC/IST&nbsp;2006</a>
						</div>
						<a href="https://web.archive.org/web/2006/http://mkg.iti.gr/ist2006/index.html"><em>Workshop on Knowledge in Multimedia Content</em></a><br>
						<a href="https://web.archive.org/web/2006/http://europa.eu.int/information_society/istevent/2006/">Information Society Technologies Event 2006</a>
						<div class="cv-ref">
							Helsinki, Finland <span class="bull"></span> Nov 22, 2006
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2006-boemie/ekaw"></a>
						<div class="cv-year">
							2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Organizer</span>
				
							<a class="but acro" href="https://web.archive.org/web/2006/http://www.boemie.org/boemie2006">BOEMIE/EKAW&nbsp;2006</a>
						</div>
						<a href="https://web.archive.org/web/2006/http://www.boemie.org/boemie2006"><em>Workshop on Ontology Evolution and Multimedia Information Extraction</em></a><br>
						<a href="https://web.archive.org/web/2006/https://ekaw.vse.cz/">15th International Conference on Knowledge Engineering and Knowledge Management</a>
						<div class="cv-ref">
							Podebrady, Czech Republic <span class="bull"></span> Oct 2-6, 2006
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2006-smar/vie"></a>
						<div class="cv-year">
							2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Organizer</span>
				
							<a class="but acro" href="https://web.archive.org/web/2006/http://www.iee.org/Events/VIE2006.cfm">SMAR/VIE&nbsp;2006</a>
						</div>
						<em>Special Session on Semantic Multimedia Analysis for Annotation and Retrieval</em><br>
						<a href="https://web.archive.org/web/2006/http://www.iee.org/Events/VIE2006.cfm">International Conference on Visual Information Engineering</a>
						<div class="cv-ref">
							Bangalore, India <span class="bull"></span> Sep 26-28, 2006
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2006-siva/icann"></a>
						<div class="cv-year">
							2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Organizer</span>
				
							<a class="but acro" href="https://web.archive.org/web/2006/http://icann2006.org/ssessions/ss4.pdf">SIVA/ICANN&nbsp;2006</a>
						</div>
						<a href="https://web.archive.org/web/2006/http://icann2006.org/ssessions/ss4.pdf"><em>Special Session on Neural Networks for Semantic Image and Video Analysis</em></a><br>
						<a href="https://web.archive.org/web/2006/http://icann2006.org/">International Conference on Artificial Neural Networks</a>
						<div class="cv-ref">
							Athens, Greece <span class="bull"></span> Sep 10-14, 2006
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2006-icann"></a>
						<div class="cv-year">
							2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Local Organizing Committee member</span>
				
							<a class="but acro" href="https://web.archive.org/web/2006/http://icann2006.org/">ICANN&nbsp;2006</a>
						</div>
						<a href="https://web.archive.org/web/2006/http://icann2006.org/">International Conference on Artificial Neural Networks</a>
						<div class="cv-ref">
							Athens, Greece <span class="bull"></span> Sep 10-14, 2006
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2005-ewimt"></a>
						<div class="cv-year">
							2005
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Special Sessions Organizer</span>
				
							<a class="but acro" href="https://web.archive.org/web/2005/http://www.acemedia.org/ewimt2005">EWIMT&nbsp;2005</a>
						</div>
						<a href="https://web.archive.org/web/2005/http://www.acemedia.org/ewimt2005">2nd European Workshop on the Integration of Knowledge, Semantic and Digital Media Technologies</a>
						<div class="cv-ref">
							London, UK <span class="bull"></span> Nov 30-Dec 1, 2005
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2005-ims/icann"></a>
						<div class="cv-year">
							2005
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Co-Organizer</span>
				
							<a class="but acro" href="https://web.archive.org/web/2005/http://www.ibspan.waw.pl/ICANN-2005">IMS/ICANN&nbsp;2005</a>
						</div>
						<em>Special Session on Intelligent Multimedia and Semantics</em><br>
						<a href="https://web.archive.org/web/2005/http://www.ibspan.waw.pl/ICANN-2005">International Conference on Artificial Neural Networks</a>
						<div class="cv-ref">
							Warsaw, Poland <span class="bull"></span> Sep 11-15, 2005
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2005-multimine"></a>
						<div class="cv-year">
							2005
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Program Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2005/http://www.multimine.gr/hmerida2.htm">MultiMine&nbsp;2005</a>
						</div>
						<a href="https://web.archive.org/web/2005/http://www.multimine.gr/hmerida2.htm">Workshop on Multimedia Knowledge Discovery and Management</a>
						<div class="cv-ref">
							Athens, Greece <span class="bull"></span> Jun 28, 2005
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2005-mmsw/eswc"></a>
						<div class="cv-year">
							2005
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Local Arrangements</span>
				
							<a class="but acro" href="https://web.archive.org/web/2005/http://www.acemedia.org/ESWC2005_MSW/">MMSW/ESWC&nbsp;2005</a>
						</div>
						<em>Workshop on Multimedia and the Semantic Web</em><br>
						<a href="https://web.archive.org/web/2005/http://www.acemedia.org/ESWC2005_MSW/">2nd European Semantic Web Conference</a>
						<div class="cv-ref">
							Heraklion, Greece <span class="bull"></span> May 29-Jun 1, 2005
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2004-civr"></a>
						<div class="cv-year">
							2004
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Session Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2004/http://www.civr2004.org/">CIVR&nbsp;2004</a>
						</div>
						<em>EU Project Session</em><br>
						<a href="https://web.archive.org/web/2004/http://www.civr2004.org/">ACM International Conference on Image and Video Retrieval</a>
						<div class="cv-ref">
							Dublin, Ireland <span class="bull"></span> Jul 21-23, 2004
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2003-wiaac"></a>
						<div class="cv-year">
							2003
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Program Co-Chair</span>
				
							<a class="but acro" href="https://web.archive.org/web/2003/http://image.ntua.gr/wiaac">WIAAC&nbsp;2003</a>
						</div>
						<a href="https://web.archive.org/web/2003/http://image.ntua.gr/wiaac">Workshop on Intelligent Access to Audiovisual Content</a>
						<div class="cv-ref">
							Athens, Greece <span class="bull"></span> Apr 3, 2003
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-2001-vlbv"></a>
						<div class="cv-year">
							2001
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Liaison with Industry, Local Organization Committee</span>
				
							<a class="but acro" href="https://web.archive.org/web/2001/http://image.ntua.gr/vlbv01">VLBV&nbsp;2001</a>
						</div>
						<a href="https://web.archive.org/web/2001/http://image.ntua.gr/vlbv01">International Workshop on Very Low Bitrate Video Coding</a>
						<div class="cv-ref">
							Athens, Greece <span class="bull"></span> Oct 11-12, 2001
						</div>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="act-1997-wann"></a>
						<div class="cv-year">
							1997
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Local Arrangements</span>
				
							<span class="acro but">WANN&nbsp;1997</span>
						</div>
						International Workshop on Applications and Perspectives of Neural Network Technology in Greece and the Broader Balkan Area
						<div class="cv-ref">
							Athens, Greece <span class="bull"></span> Feb 21, 1997
						</div>
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="jury"></a>
					<span class="mr">PhD juries</span>
					<i class="fal fa-diploma"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="jury-2020-engilberge"></a>
						<div class="cv-year">
							2020
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Reviewer and Jury member</span>
						</div>
						<a href="https://martin.engilberge.io/">Martin Engilberge</a><br>
						Paris-Sorbonne Université <span class="bull"></span> France
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="jury-2020-bordes"></a>
						<div class="cv-year">
							2020
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Reviewer and Jury member</span>
						</div>
						<a href="https://www.lip6.fr/actualite/personnes-fiche.php?ident=D2136">Patrick Bordes</a><br>
						Paris-Sorbonne Université <span class="bull"></span> France
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="jury-2011-vieux"></a>
						<div class="cv-year">
							2011
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Reviewer and Jury member</span>
						</div>
						<a href="https://fr.linkedin.com/in/remi-vieux-73498756">Rémi Vieux</a><br>
						Université de Bordeaux <span class="bull"></span> France
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="jury-2008-vallet"></a>
						<div class="cv-year">
							2008
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Thesis Reviewer</span>
						</div>
						<a href="http://ir.ii.uam.es/~dvallet/">David Vallet</a><br>
						Universidad Autonoma de Madrid <span class="bull"></span> Spain
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="eval"></a>
					<span class="mr">Evaluator activities</span>
					<i class="fal fa-balance-scale"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eval-2021-deepcube"></a>
						<div class="cv-year">
							2021-2023
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Member of Advisory Board</span>
				
							<a class="but acro" href="https://cordis.europa.eu/project/id/101004188">DeepCube</a>
						</div>
						<a href="https://cordis.europa.eu/project/id/101004188"><em>H2020 project DeepCube</em></a><br>
						European Commission
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eval-2021-isf"></a>
						<div class="cv-year">
							2021
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Proposal Reviewer</span>
				
							<a class="but acro" href="https://isf.org.il/">ISF</a>
						</div>
						<a href="https://isf.org.il/">Israel Science Foundation</a>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eval-2020-seda"></a>
						<div class="cv-year">
							2020
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Project Reviewer and Rapporteur</span>
				
							<a class="but acro" href="https://www.viaa.gov.lv/eng/">SEDA</a>
						</div>
						<em>Post-Doctoral Research project</em><br>
						<a href="https://www.viaa.gov.lv/eng/">State Education Development Agency</a>
						<span class="bull"></span> Latvia
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eval-2017-seda"></a>
						<div class="cv-year">
							2017-2018
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Proposal Reviewer and Rapporteur</span>
				
							<a class="but acro" href="https://web.archive.org/web/2017/https://www.viaa.gov.lv/eng/">SEDA</a>
						</div>
						<a href="https://web.archive.org/web/2017/https://www.viaa.gov.lv/eng/">State Education Development Agency</a>
						<span class="bull"></span> Latvia
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eval-2017-anr"></a>
						<div class="cv-year">
							2017-2021
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Proposal Reviewer</span>
				
							<a class="but acro" href="https://web.archive.org/web/2017/https://anr.fr/en/">ANR</a>
						</div>
						<a href="https://web.archive.org/web/2017/https://anr.fr/en/">Agence Nationale de la Recherche</a>
						<span class="bull"></span> France
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="eval-2010-notube"></a>
						<div class="cv-year">
							2010-2012
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Reviewer and Rapporteur</span>
				
							<a class="but acro" href="https://web.archive.org/web/2010/http://www.notube.tv/">NoTube</a>
						</div>
						<a href="https://web.archive.org/web/2010/http://www.notube.tv/"><em>FP7-231761 Integrated Project NoTube</em></a><br>
						European Commission, DG Information Society and Media, Unit E2
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="edit"></a>
					<span class="mr">Editorial activities</span>
					<i class="fal fa-pen-nib"></i>
				</h1>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="edit-2021-cviu"></a>
						<div class="cv-year">
							2021-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Associate Editor</span>
				
							<a class="but acro" href="https://www.journals.elsevier.com/computer-vision-and-image-understanding/">CVIU</a>
						</div>
						<a href="https://www.journals.elsevier.com/computer-vision-and-image-understanding/">Computer Vision and Image Understanding</a><br>
					</div>
				</div>
				<div class="row cv-row">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="edit-2009-jivp"></a>
						<div class="cv-year">
							2009-2014
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<span class="mr">Associate Editor</span>
				
							<a class="but acro" href="https://web.archive.org/web/2009/http://www.hindawi.com/journals/ivp/">JIVP</a>
						</div>
						<a href="https://web.archive.org/web/2009/http://www.hindawi.com/journals/ivp/">EURASIP Journal on Image and Video Processing</a><br>
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="journ"></a>
					<span class="mr">Reviewer in journals</span>
					<i class="fal fa-book-reader"></i>
				</h1>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2021-ijcv"></a>
						<div class="cv-year">
							2021-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://www.springer.com/journal/11263">International Journal of Computer Vision</a>
				
							<a class="but acro" href="https://www.springer.com/journal/11263">IJCV</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2014-csur"></a>
						<div class="cv-year">
							2014
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="http://csur.acm.org/">ACM Computing Surveys</a>
				
							<a class="but acro" href="http://csur.acm.org/">CSUR</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2012-ivc"></a>
						<div class="cv-year">
							2012
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://www.journals.elsevier.com/image-and-vision-computing/">Elsevier: Image and Vision Computing</a>
				
							<a class="but acro" href="https://www.journals.elsevier.com/image-and-vision-computing/">IVC</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2008-cviu"></a>
						<div class="cv-year">
							2008-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://www.journals.elsevier.com/computer-vision-and-image-understanding">Elsevier: Computer Vision and Image Understanding</a>
				
							<a class="but acro" href="https://www.journals.elsevier.com/computer-vision-and-image-understanding">CVIU</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2007-neucom"></a>
						<div class="cv-year">
							2007-2016
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://www.journals.elsevier.com/neurocomputing">Elsevier: Neurocomputing</a>
				
							<a class="but acro" href="https://www.journals.elsevier.com/neurocomputing">NEUCOM</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2006-sp:ic"></a>
						<div class="cv-year">
							2006-2010
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://www.journals.elsevier.com/signal-processing-image-communication/">Elsevier: Signal Processing: Image Communication</a>
				
							<a class="but acro" href="https://www.journals.elsevier.com/signal-processing-image-communication/">SP:IC</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2006-tevc"></a>
						<div class="cv-year">
							2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://cis.ieee.org/publications/t-evolutionary-computation">IEEE Transactions on Evolutionary Computation</a>
				
							<a class="but acro" href="https://cis.ieee.org/publications/t-evolutionary-computation">TEVC</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2005-tmm"></a>
						<div class="cv-year">
							2005-2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-multimedia">IEEE Transactions on Multimedia</a>
				
							<a class="but acro" href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-multimedia">TMM</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2004-iee-vis"></a>
						<div class="cv-year">
							2004-2005
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://digital-library.theiet.org/content/journals/ip-vis">IEE Proceedings on Vision, Image and Signal Processing</a>
				
							<a class="but acro" href="https://digital-library.theiet.org/content/journals/ip-vis">IEE-VIS</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2004-tcsvt"></a>
						<div class="cv-year">
							2004-2008
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="http://ieee-cas.org/pubs/tcsvt">IEEE Transactions on Circuits and Systems for Video Technology</a>
				
							<a class="but acro" href="http://ieee-cas.org/pubs/tcsvt">TCSVT</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2004-tpami"></a>
						<div class="cv-year">
							2004-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://www.computer.org/web/tpami">IEEE Transactions on Pattern Analysis and Machine Intelligence</a>
				
							<a class="but acro" href="https://www.computer.org/web/tpami">TPAMI</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2004-mtap"></a>
						<div class="cv-year">
							2004-2016
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://www.springer.com/computer/information+systems+and+applications/journal/11042">Springer: Multimedia Tools and Applications</a>
				
							<a class="but acro" href="https://www.springer.com/computer/information+systems+and+applications/journal/11042">MTAP</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2004-paa"></a>
						<div class="cv-year">
							2004
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://www.springer.com/computer/image+processing/journal/10044">Springer: Pattern Analysis and Applications</a>
				
							<a class="but acro" href="https://www.springer.com/computer/image+processing/journal/10044">PAA</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2003-jasp"></a>
						<div class="cv-year">
							2003
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2003/http://asp.hindawi.com/">EURASIP Journal of Applied Signal Processing</a>
				
							<a class="but acro" href="https://web.archive.org/web/2003/http://asp.hindawi.com/">JASP</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2002-tip"></a>
						<div class="cv-year">
							2002
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-image-processing">IEEE Transactions on Image Processing</a>
				
							<a class="but acro" href="https://signalprocessingsociety.org/publications-resources/ieee-transactions-image-processing">TIP</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="journ-2002-mva"></a>
						<div class="cv-year">
							2002
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://www.springer.com/computer/image+processing/journal/138">Springer: Machine Vision and Applications</a>
				
							<a class="but acro" href="https://www.springer.com/computer/image+processing/journal/138">MVA</a>
						</div>
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="conf"></a>
					<span class="mr">Program Committee member in conferences</span>
					<i class="fal fa-book-reader"></i>
				</h1>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2013-iccv"></a>
						<div class="cv-year">
							2013-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2013/http://www.iccv2013.org/">International Conference on Computer Vision</a>
				
							<a class="but acro" href="https://web.archive.org/web/2013/http://www.iccv2013.org/">ICCV</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2013-cvpr"></a>
						<div class="cv-year">
							2013-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2013/http://www.pamitc.org/cvpr13/">IEEE Conference on Computer Vision and Pattern Recognition</a>
				
							<a class="but acro" href="https://web.archive.org/web/2013/http://www.pamitc.org/cvpr13/">CVPR</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2012-eccv"></a>
						<div class="cv-year">
							2012-
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2012/http://eccv2012.unifi.it/">European Conference on Computer Vision</a>
				
							<a class="but acro" href="https://web.archive.org/web/2012/http://eccv2012.unifi.it/">ECCV</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2012-bmvc"></a>
						<div class="cv-year">
							2012-2016
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2012/http://bmvc2012.surrey.ac.uk/">British Machine Vision Conference</a>
				
							<a class="but acro" href="https://web.archive.org/web/2012/http://bmvc2012.surrey.ac.uk/">BMVC</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2012-icmr"></a>
						<div class="cv-year">
							2012
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2012/http://www.icmr2012.org/">ACM International Conference on Multimedia Retrieval</a>
				
							<a class="but acro" href="https://web.archive.org/web/2012/http://www.icmr2012.org/">ICMR</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2009-mmm"></a>
						<div class="cv-year">
							2009-2013
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2009/http://mmm2009.eurecom.fr/">International Multimedia Modeling Conference</a>
				
							<a class="but acro" href="https://web.archive.org/web/2009/http://mmm2009.eurecom.fr/">MMM</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2009-dsp"></a>
						<div class="cv-year">
							2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2009/http://www.dsp2009.org/">International Conference on Digital Signal Processing</a>
				
							<a class="but acro" href="https://web.archive.org/web/2009/http://www.dsp2009.org/">DSP</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2007-acm-mm"></a>
						<div class="cv-year">
							2007-2016
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2007/http://mmc36.informatik.uni-augsburg.de/acmmm2007/">ACM Multimedia Conference</a>
				
							<a class="but acro" href="https://web.archive.org/web/2007/http://mmc36.informatik.uni-augsburg.de/acmmm2007/">ACM-MM</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2007-civr"></a>
						<div class="cv-year">
							2007-2008
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2019/https://ivi.fnwi.uva.nl/isis/events/civr2007/">ACM International Conference on Image and Video Retrieval</a>
				
							<a class="but acro" href="https://web.archive.org/web/2019/https://ivi.fnwi.uva.nl/isis/events/civr2007/">CIVR</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2007-eusipco"></a>
						<div class="cv-year">
							2007
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2007/http://www.eusipco2007.org/">European Signal Processing Conference</a>
				
							<a class="but acro" href="https://web.archive.org/web/2007/http://www.eusipco2007.org/">EUSIPCO</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2007-icme"></a>
						<div class="cv-year">
							2007-2017
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2007/http://research.microsoft.com/conferences/ICME07/">International Conference on Multimedia and Expo</a>
				
							<a class="but acro" href="https://web.archive.org/web/2007/http://research.microsoft.com/conferences/ICME07/">ICME</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2006-vie"></a>
						<div class="cv-year">
							2006-2007
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2006/http://www.iee.org/Events/VIE2006.cfm">International Conference on Visual Information Engineering</a>
				
							<a class="but acro" href="https://web.archive.org/web/2006/http://www.iee.org/Events/VIE2006.cfm">VIE</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2005-icassp"></a>
						<div class="cv-year">
							2005-2017
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2005/http://www.icassp2005.com/">IEEE International Conference on Acoustics, Speech, and Signal Processing</a>
				
							<a class="but acro" href="https://web.archive.org/web/2005/http://www.icassp2005.com/">ICASSP</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2004-icip"></a>
						<div class="cv-year">
							2004-2016
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2004/http://www.icip2004.org/">IEEE International Conference on Image Processing</a>
				
							<a class="but acro" href="https://web.archive.org/web/2004/http://www.icip2004.org/">ICIP</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="conf-2002-icann"></a>
						<div class="cv-year">
							2002-2009
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2002/http://www.ii.uam.es/icann2002">International Conference on Artificial Neural Networks</a>
				
							<a class="but acro" href="https://web.archive.org/web/2002/http://www.ii.uam.es/icann2002">ICANN</a>
						</div>
					</div>
				</div>
				<h1 class="cv rule">
					<a class="anchor" id="work"></a>
					<span class="mr">Program Committee member in workshops</span>
					<i class="fal fa-book-reader"></i>
				</h1>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="work-2006-mtg"></a>
						<div class="cv-year">
							2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2006/http://tev.itc.it/mtg.html">ESWC Workshop on Mastering the Gap: From Information Extraction to Semantic Representation</a>
				
							<a class="but acro" href="https://web.archive.org/web/2006/http://tev.itc.it/mtg.html">MTG</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="work-2006-swamm"></a>
						<div class="cv-year">
							2006
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2006/http://multimedia.semanticweb.org/">International Workshop on Semantic Web Annotations for Multimedia</a>
				
							<a class="but acro" href="https://web.archive.org/web/2006/http://multimedia.semanticweb.org/">SWAMM</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="work-2005-ewimt"></a>
						<div class="cv-year">
							2005
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2005/http://www.acemedia.org/ewimt2005">European Workshop on the Integration of Knowledge, Semantic and Digital Media Technologies</a>
				
							<a class="but acro" href="https://web.archive.org/web/2005/http://www.acemedia.org/ewimt2005">EWIMT</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="work-2005-wiamis"></a>
						<div class="cv-year">
							2005-2013
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/200504/http://www.wiamis2005.ch/">Workshop on Image Analysis for Multimedia Interactive Services</a>
				
							<a class="but acro" href="https://web.archive.org/web/200504/http://www.wiamis2005.ch/">WIAMIS</a>
						</div>
					</div>
				</div>
				<div class="row cv-row-thin">
					<div class="col-sm-auto cv-year-col">
						<a class="anchor" id="work-2003-cbmi"></a>
						<div class="cv-year">
							2003-2016
						</div>
					</div>
					<div class="col-sm">
						<div class="cv-title">
							<a class="mr" href="https://web.archive.org/web/2003/http://www.irisa.fr/manifestations/2003/CBMI03">International Workshop on Content-Based Multimedia Indexing</a>
				
							<a class="but acro" href="https://web.archive.org/web/2003/http://www.irisa.fr/manifestations/2003/CBMI03">CBMI</a>
						</div>
					</div>
				</div>
			</div>
		</main>

	</div>
</div>

	</body>
</html>